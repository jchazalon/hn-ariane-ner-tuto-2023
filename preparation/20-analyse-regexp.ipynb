{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse 1 : utilisation de regexp et de patterns spacy\n",
    "\n",
    "on essaie d'extraire des termes connus, et des locutions typiques, pour d√©tecter les r√©f√©rences aux personnages et aux lieux.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouver et lister les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME fournir code lecture fichiers depuis Google Drive ici (archive format zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEXT_FILES_DIR = \"/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00101_Adam.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00102_Adam.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00201_Audoux.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00301_Aimard.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00302_Aimard.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00401_Allais.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00501_Balzac.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00502_Balzac.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00503_Balzac.txt',\n",
       " '/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00601_Boisgobey.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob(os.path.join(PATH_TEXT_FILES_DIR, \"*.txt\")))\n",
    "print(\"Found\", len(files), \"files.\")\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/joseph/tmp/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03001_Ohnet.txt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = files[50]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import spacy and start processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## L'objet `nlp`\n",
    "On construit une nouvelle cha√Æne de traitements de plusieurs fa√ßon. La mani√®re la plus simple est de construire une cha√Æne de traitement vide (ou presque) pour le fran√ßais √† l'aide de la \"fabrique\" √† cha√Ænes de traitement `spacy.blank(LANGAGE)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La cha√Æne de traitements contient diff√©rents traitements appliqu√©s les uns apr√®s les autres.\n",
    "On peut afficher cette liste de traitements √† l'aide de l'attribut `pipe_names` de l'objet `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, une cha√Æne de traitement ne contient rien‚Ä¶ Sauf un *tokenizer*, d'o√π l'importance de pr√©ciser la langue !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'objet `doc`\n",
    "On obtient un objet `doc` en appliquant la cha√Æne de traitement `nlp` √† une cha√Æne de texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©√© en traitant une chaine de caract√®res avec l'objet nlp\n",
    "doc = nlp(\"Bonjour tout le monde !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet objet `doc` est central pour Spacy : il contient toute les informations produite par la cha√Æne de traitement √† propos de notre texte.\n",
    "\n",
    "On peut parcourir les *tokens* extraits √† l'aide d'une boucle classique en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour\n",
      "tout\n",
      "le\n",
      "monde\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# It√®re sur les tokens dans un Doc\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tout"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut s√©lectionner un token particulier, gr√¢ce √† son indice dans le document\n",
    "token = doc[1]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de cellule avec contenu cach√© par d√©faut\n",
    "#### üöß <b>Essayez √† pr√©sent de s√©lectionner et afficher les <i>tokens</i> \"tout le monde\".</b>\n",
    "\n",
    "<details>\n",
    "<summary>Indices</summary>\n",
    "\n",
    "Vous pouvez utiliser les *ranges* pour s√©lectionner plusieurs √©l√©ments d'un it√©rable. Voici un exemple de la syntaxe √† utiliser :\n",
    "```python\n",
    "ma_liste = [0, 1, 2, 3]\n",
    "print(ma_liste[1:3])\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "On applique cette syntaxe pour s√©lectionner les tokens du rang 1 (2e token, inclus) au rang 4 (non inclus) :\n",
    "\n",
    "```python\n",
    "doc[1:4]\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tout le monde"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut √©galement utiliser les \"ranges\" Python pour s√©lectionner plusieurs tokens\n",
    "span = doc[1:4]\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tout le monde'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut √©galement acc√©der aux attributs d'un span\n",
    "span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on souhaite traiter plusieurs documents, on peut utiliser `nlp.pipe(LISTE_DE_TEXTES)`.\n",
    "Dans ce cas, on obtient une liste de documents en sortie, qu'il est possible d'inspecter avec une seconde boucle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc#0, tok#0: Bonjour\n",
      "doc#0, tok#1: tout\n",
      "doc#0, tok#2: le\n",
      "doc#0, tok#3: monde\n",
      "doc#0, tok#4: !\n",
      "doc#1, tok#0: Comment\n",
      "doc#1, tok#1: allez\n",
      "doc#1, tok#2: -vous\n",
      "doc#1, tok#3: ?\n",
      "doc#1, tok#4: Bien\n",
      "doc#1, tok#5: ,\n",
      "doc#1, tok#6: j'\n",
      "doc#1, tok#7: esp√®re\n",
      "doc#1, tok#8: !\n",
      "doc#2, tok#0: Savez\n",
      "doc#2, tok#1: -vous\n",
      "doc#2, tok#2: qu'\n",
      "doc#2, tok#3: une\n",
      "doc#2, tok#4: cha√Æne\n",
      "doc#2, tok#5: de\n",
      "doc#2, tok#6: caract√®res\n",
      "doc#2, tok#7: peut\n",
      "doc#2, tok#8: contenir\n",
      "doc#2, tok#9: des\n",
      "doc#2, tok#10: retours\n",
      "doc#2, tok#11: √†\n",
      "doc#2, tok#12: la\n",
      "doc#2, tok#13: ligne\n",
      "doc#2, tok#14: \n",
      "\n",
      "doc#2, tok#15: comme\n",
      "doc#2, tok#16: celui-ci\n",
      "doc#2, tok#17: ?\n"
     ]
    }
   ],
   "source": [
    "TEXTES = [\n",
    "    \"Bonjour tout le monde !\", \n",
    "    \"Comment allez-vous ? Bien, j'esp√®re !\",\n",
    "    \"Savez-vous qu'une cha√Æne de caract√®res peut contenir des retours √† la ligne\\ncomme celui-ci ?\"\n",
    "    ]\n",
    "documents = nlp.pipe(TEXTES)\n",
    "for doc_id, doc in enumerate(documents):\n",
    "    for token in doc:\n",
    "        print(f\"doc#{doc_id}, tok#{token.i}: {token.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :    [0, 1, 2, 3, 4]\n",
      "Text :     ['Cela', 'co√ªte', '5', '‚Ç¨', '.']\n",
      "is_alpha : [True, True, False, False, False]\n",
      "is_punct : [False, False, False, False, True]\n",
      "like_num : [False, False, True, False, False]\n"
     ]
    }
   ],
   "source": [
    "## Autres attributs des tokens et des spans\n",
    "\n",
    "doc = nlp(\"Cela co√ªte 5 ‚Ç¨.\")\n",
    "\n",
    "print(\"Index :   \", [token.i for token in doc])\n",
    "print(\"Text :    \", [token.text for token in doc])\n",
    "\n",
    "print(\"is_alpha :\", [token.is_alpha for token in doc])\n",
    "print(\"is_punct :\", [token.is_punct for token in doc])\n",
    "print(\"like_num :\", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        La    DET          det    journ√©e\n",
      "   journ√©e   NOUN        nsubj    d√©roule\n",
      "        de    ADP         case  formation\n",
      " formation   NOUN         nmod    journ√©e\n",
      "         √†    ADP         case       Lyon\n",
      "      Lyon  PROPN         nmod    journ√©e\n",
      "        se   PRON    expl:comp    d√©roule\n",
      "   d√©roule   VERB         ROOT    d√©roule\n",
      "      bien    ADV       advmod    d√©roule\n",
      "         .  PUNCT        punct    d√©roule\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process a text\n",
    "doc = nlp(\"La journ√©e de formation √† Lyon se d√©roule bien.\")\n",
    "for token in doc:\n",
    "    # print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "    print(f\"{token.text:>10s}\", f\"{token.pos_:>6s}\", f\"{token.dep_:>12s}\", f\"{token.head.text:>10s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">La journ√©e de formation √† \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lyon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " se d√©roule bien.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'un pipeline avec un pos_tagger et un reconnaisseur d'entit√©s nomm√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from fr-core-news-sm==3.7.0) (3.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.3)\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filename: str) -> str:\n",
    "    with open(filename, encoding=\"utf8\") as in_file:\n",
    "        return \"\".join(in_file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "Dans un de ces charmants chemins creux de Normandie, serpentant entre les lev√©es, plant√©es de grands arbres, qui entourent les fermes d'un rempart de verdure imp√©n√©trable au vent et au soleil, par une belle matin√©e d'√©t√©, une amazone, mont√©e sur une jument de forme assez m√©diocre, s'avan√ßait au pas, les r√™nes abandonn√©es, r√™veuse, respirant l'air ti√®de, embaum√© du parfum des tr√®fles en fleurs. Avec son chapeau de feutre noir entour√© d'un voile de gaze blanche, son costume de drap gris fer √† longue jupe, elle avait fi√®re tournure. On e√ªt dit une de ces aventureuses grandes dames qui, au temps de Stofflet et de Cathelineau, suivaient hardiment l'arm√©e royaliste, dans les tra√Ænes du Bocage, et √©clairaient de leur sourire la sombre √©pop√©e vend√©enne.\n",
      "√âl√©gante et svelte, elle se laissait aller gracieusement au mouvement de sa monture, fouettant distraitement de sa cravache les tiges vertes des gen√™ts. Un l√©vrier d'√âcosse au poil rude et rouge√¢tre l'accompagnait, r√©glant son allure souple sur la marche lass√©e du cheval, et levant, de temps en temps, vers sa ma√Ætresse, sa t√™te pointue, √©clair√©e par deux yeux noirs qui brillaient sous des sourcils en broussailles. L'herbe courte et grasse, qui poussait sous la vo√ªte sombre des h√™tres, √©tendait devant la promeneuse un tapis moelleux comme du velours. Dans les herbages, les vaches appesanties tendaient vers la fra√Æcheur du chemin leurs mufles tourment√©s par les mouches. Pas un souffle de vent n'agitait les feuilles. Sous les feux du soleil l'air vibrait embras√©, et une torpeur lourde pesait sur la terre.\n",
      "La t√™te pench√©e sur la poitrine, absorb√©e, l'amazone allait, indiff√©rente au charme de ce chemin plein d'ombre et de silence.\n",
      "Soudainement, son cheval fit un √©cart, pointa les oreilles, et faillit se renverser, soufflant bruyamment, tandis que le l√©vrier, s'√©lan√ßant en avant, aboyait avec fureur, et montrait √† un homme qui venait de sauter dans le chemin creux une double rang√©e de dents aigu√´s et grin√ßantes.\n",
      "L'amazone, tir√©e brutalement de sa m√©ditation, rassembla les r√™nes, ramena son cheval et, s'assurant sur sa selle, adressa √† l'auteur de tout ce trouble un regard plus √©tonn√© que m√©content.\n",
      "‚Äî Je vous demande bien pardon, Madame, dit celui-ci d'une voix pleine et sonore... Je me suis tr√®s maladroitement √©lanc√© en travers de votre route... Je ne vous entendais pas arriver... Il y a plus d'une heure que je tourne dans ces herbages sans pouvoir en sortir... Toutes les barri√®res des cours sont cadenass√©es, et les haies sont trop hautes pour qu'on puisse les franchir... Enfin j'ai trouv√© ce petit chemin cach√© sous les arbres, et, en y prenant pied, j'ai failli vous faire jeter √† terre...\n",
      "L'amazone sourit un peu, et son visage aux traits nobles et d√©licats prit une expression enjou√©e et charmante :\n",
      "‚Äî Rassurez-vous, Monsieur : vous n'√™tes pas tr√®s coupable, et je ne tombe pas de cheval si facilement que vous paraissez le croire...\n",
      "Et comme son l√©vrier continuait √† gronder en mena√ßant:\n",
      "‚Äî Allons, Fox, la paix ! dit-elle.\n",
      "Le chien se retourna et, se m√¢tant sur ses pattes de derri√®re, posa son museau fin sur la main de sa ma√Ætresse. Celle-ci, tout en caressant le l√©vrier, examinait son interlocuteur. C'√©tait un homme d'une trentaine d'ann√©es, de haute taille, au visage √©nergique, encadr√© d'une √©paisse barbe brune. Sa l√®vre ras√©e et son teint basan√© lui donnaient l'air d'un marin. Il √©tait v√™tu d'un costume complet de drap chin√©, coiff√© d'un chapeau de feutre mou, et √† la main il tenait une canne en bois de fer, mieux faite pour la bataille que pour la promenade.\n",
      "‚Äî Vous n'√™tes pas de ce pays ? demanda alors l'amazone.\n",
      "‚Äî Je suis ici seulement depuis hier, dit l'√©tranger, sans r√©pondre √† la question qui lui √©tait pos√©e... J'ai eu la fantaisie d'aller me promener ce matin dans la campagne, et je me suis √©gar√©... J'ai pourtant l'habitude de m'orienter... Mais ces diables de petits chemins qui n'aboutissent √† rien forment un labyrinthe inextricable...\n",
      "‚Äî O√π d√©sirez-vous aller ?\n",
      "‚Äî √Ä La Neuville...\n",
      "‚Äî Tr√®s bien ! Vous lui tournez le dos... Si vous voulez me suivre pendant quelques instants, je vous mettrai dans une route o√π vous ne risquerez plus de vous perdre...\n",
      "‚Äî Bien volontiers, Madame... Mais j'esp√®re que vous ne vous √©loignerez pas de la direction que vous suiviez...\n",
      "L'amazone secoua gravement la t√™te, et dit:\n",
      "‚Äî Cela ne me d√©tourne point d'un seul pas... L'√©tranger fit un signe d'acquiescement, et, s√©par√© de la jeune femme par le l√©vrier, qui ne revenait pas de son antipathie et trottait en grondant sourdement, il suivit la fra√Æche et verte perc√©e, ne parlant pas, mais admirant la beaut√© rayonnante de son guide. Par moments, des branches basses, pendant des troncs d'arbres, barraient le chemin, et l'amazone √©tait oblig√©e de courber la t√™te pour les √©viter. Dans ce mouvement, sous son feutre, apparaissait sa nuque blanche sur laquelle frisaient des m√®ches folles, et son pur profil se d√©tachait sur le fond sombre de la verdure. Elle se penchait souple et se redressait avec une gr√¢ce √©l√©gante et simple, ne paraissant pas se douter qu'elle √©tait admir√©e, et, soit par fiert√©, soit par insouciance, ne tenant aucun compte du compagnon que le hasard lui avait donn√©. Au repos, son visage exprimait une gravit√© m√©lancolique, comme si elle vivait sous l'empire d'une habituelle tristesse. Quels chagrins pouvait avoir cette jeune et belle personne cr√©√©e pour √™tre servie, choy√©e et ador√©e ? La destin√©e injuste lui avait-elle donn√© le malheur, √† elle faite pour la joie ? Elle semblait riche. Sa peine devait donc √™tre toute morale. Arriv√© √† ce point de ses inductions, l'√©tranger se demanda si sa compagne √©tait une jeune femme ou une jeune fille. Sa haute taille, ses √©paules rondes, dont l'harmonieuse ampleur √©tait accentu√©e par la finesse de sa ceinture, √©taient d'une femme. Mais la suavit√© velout√©e de ses joues, la fra√Æche puret√© de ses yeux trahissaient la jeune fille. Le lobe ros√© de ses oreilles n'√©tait point perc√©, et ni au cou ni aux poignets elle ne portait de bijou.\n"
     ]
    }
   ],
   "source": [
    "text = load_text(files[50])\n",
    "print(text)\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I LOC\n",
      "Normandie LOC\n",
      "Stofflet PER\n",
      "Cathelineau LOC\n",
      "Bocage LOC\n",
      "√âl√©gante ORG\n",
      "√âcosse LOC\n",
      "amazone LOC\n",
      "Madame PER\n",
      "Rassurez PER\n",
      "Monsieur PER\n",
      "Allons PER\n",
      "Fox ORG\n",
      "O√π MISC\n",
      "La Neuville LOC\n",
      "Madame PER\n"
     ]
    }
   ],
   "source": [
    "# It√®re sur les entit√©s pr√©dites\n",
    "for ent in doc.ents:\n",
    "    # Affiche le texte de l'entit√© et son label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non-GPE locations, mountain ranges, bodies of water'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"LOC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation du matcher Spacy\n",
    "TODO montrer comment filtrer sur lex√®me, nature ou fonction du token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"POS\": \"PROPN\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.explain(\"PROPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"NOMS_PROPRES\", [pattern])\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de correspondances trouv√©es : 10\n",
      "Correspondance trouv√©e : Normandie\n",
      "Correspondance trouv√©e : Stofflet\n",
      "Correspondance trouv√©e : Cathelineau\n",
      "Correspondance trouv√©e : √âcosse\n",
      "Correspondance trouv√©e : Rassurez\n",
      "Correspondance trouv√©e : Allons\n",
      "Correspondance trouv√©e : Fox\n",
      "Correspondance trouv√©e : Neuville\n",
      "Correspondance trouv√©e : volontiers\n",
      "Correspondance trouv√©e : hasard\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de correspondances trouv√©es :\", len(matches))\n",
    "\n",
    "# It√®re sur les correspondances et affiche la portion de texte\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Correspondance trouv√©e :\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ouverture : utilisation de la biblioth√®que Transformers\n",
    "\n",
    "# https://huggingface.co/Jean-Baptiste/camembert-ner (m√™me API !)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "\n",
    "\n",
    "##### Process text sample (from wikipedia)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "nlp(\"Apple est cr√©√©e le 1er avril 1976 dans le garage de la maison d'enfance de Steve Jobs √† Los Altos en Californie par Steve Jobs, Steve Wozniak et Ronald Wayne14, puis constitu√©e sous forme de soci√©t√© le 3 janvier 1977 √† l'origine sous le nom d'Apple Computer, mais pour ses 30 ans et pour refl√©ter la diversification de ses produits, le mot ¬´ computer ¬ª est retir√© le 9 janvier 2015.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hn-ariane-ner-tuto-2023-5IA5eVhR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
