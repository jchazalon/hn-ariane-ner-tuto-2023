{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiation √† la üîé reconnaissance d'entit√©s nomm√©es üîç avec [Spacy](https://spacy.io/)\n",
    "\n",
    "<p style=\"font-size:small;font-style:italic\">Notebook g√©n√©r√© le {{TAG_GENERATION_DATE}} √† {{TAG_GENERATION_TIME}}</p>\n",
    "<p style=\"font-size:small;\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dct=\"http://purl.org/dc/terms/\"><a property=\"dct:title\" rel=\"cc:attributionURL\" href=\"https://github.com/jchazalon/hn-ariane-ner-tuto-2023 \">Tous les supports de cette activit√©</a> cr√©√©s par <a rel=\"cc:attributionURL dct:creator\" property=\"cc:attributionName\" href=\"https://jchazalon.github.io\">Joseph Chazalon</a> sont distribu√©s selon les termes de la licence Creative Commons <a href=\"http://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1\" target=\"_blank\" rel=\"license noopener noreferrer\" style=\"display:inline-block;\">Attribution-ShareAlike 4.0 International<img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\"></a></p> \n",
    "\n",
    "[![](https://img.shields.io/badge/Google_%20_Colab-Cliquez_ici_pour_√©diter_ce_notebook-blue?logo=googlecolab)](https://colab.research.google.com/github/jchazalon/hn-ariane-ner-tuto-2023/blob/main/preparation/30-draft-final.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**üëã Bonjour !**\n",
    "\n",
    "Cette activit√© a pour objectif de vous apprendre √† utiliser la biblioth√®que [Spacy](https://spacy.io/) et de mettre en place un projet de reconnaissance d'entit√©s nomm√©es (*[Named entities recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)*, ou *NER* en anglais).\n",
    "\n",
    "Au travers d'exercices et d'observations simples qui vous permettront d'envisager la cha√Æne de traitement de donn√©es dans son ensemble, vous allez prendre en main quelques d'outils essentiels.\n",
    "Ainsi, vous devriez pouvoir r√©appliquer cette approche sur des donn√©es de votre choix, apr√®s cet atelier, en toute autonomie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Contenu de cette activit√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO auto generate TOC\n",
    "1. [5 mn] introduction\n",
    "1. [5 mn] Installation et g√©n√©ralit√©s √† propos de Spacy, manipulation des objets de base\n",
    "1. [5 mn] utilisation d'un mod√®le de langage existant pour reconnaitre des entit√©s nomm√©es\n",
    "1. [5 mn] traitement des donn√©es de notre corpus d'exemple\n",
    "1. [5 mn] √©valuation objective de la performance d'un mod√®le de langage\n",
    "1. [5 mn] aper√ßu du probl√®me d'annotation pour avoir un jeu de donn√©es complet\n",
    "1. [10 mn] comparaison de la performance de mod√®les de langage pr√©-entra√Æn√©s g√©n√©riques et entra√Ænement d'un mod√®le sp√©cialis√©\n",
    "1. [2 mn] export des donn√©es pour une utilisation ult√©rieure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üó∫Ô∏è Symboles utilis√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Au cours de cette activit√©, vous aurez des actions √† r√©aliser.\n",
    "  Celles-ci sont indiqu√©es par les symboles üöß, üèóÔ∏è, üõ†Ô∏è, üë∑.\n",
    "- Certains √©l√©ments n√©cessitant votre attention sont indiqu√©s par des symboles comme üö®, ‚ö†Ô∏è, üëâ.\n",
    "- Et finalement, certains √©l√©ments sont indiqu√©s pour vous permettre de prolonger cette activit√© en dehors du cr√©neau r√©serv√© et sont indiqu√©s par le symbole ü§ì.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources et licence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cet atelier est largement tir√© du cours ‚Äú[NLP avanc√© avec Spacy](https://course.spacy.io/fr)‚Äù r√©alis√© par [Ines Montani](https://twitter.com/_inesmontani) (cr√©atrice de [Spacy](https://spacy.io/)) sous [licence MIT](https://www.tldrlegal.com/license/mit-license).\n",
    "Cette licence nous autorise √† reprendre, modifier et diffuser son contenu tant que nous indiquons la licence originale :\n",
    "\n",
    ">The MIT License (MIT)\n",
    ">Copyright (C) 2019 Ines Montani\n",
    ">Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\n",
    "Les donn√©es de cet atelier sont adapt√©es du ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù par Carmen Brando, Francesca Frontini, et Ioana Galleron sous licence [Creative Commons - Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/). \n",
    "\n",
    "> Brando, Carmen; Frontini, Francesca and Galleron, Ioana, 2022, French ELTEC NER Open Dataset, ILC-CNR for CLARIN-IT repository hosted at Institute for Computational Linguistics \"A. Zampolli\", National Research Council, in Pisa, [http://hdl.handle.net/20.500.11752/OPEN-986](http://hdl.handle.net/20.500.11752/OPEN-986).\n",
    "\n",
    "Ce cours et les donn√©es associ√©es sont sous licence [Creative Commons - Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/).\n",
    "Pour citer ce travail, merci d'indiquer :\n",
    "\n",
    "> Consortium HumaNum Ariane, Joseph Chazalon, Atelier d'initiation √† la reconnaissance d'entit√©s nomm√©es avec Spacy, en ligne : <https://github.com/jchazalon/hn-ariane-ner-tuto-2023>, 9 novembre 2023, Lyon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ C'est parti !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le lien vers la pr√©sentation : <https://docs.google.com/presentation/d/1_RycfOOeQo8XZNojsx7SzaSDyhepj-8n8w7xMpf9UGI/edit>\n",
    "\n",
    "Vous pouvez aussi acc√©der √† tous les fichiers de cette activit√© (pour les t√©l√©charger par exemple) sur GitHub : <https://github.com/jchazalon/hn-ariane-ner-tuto-2023>\n",
    "\n",
    "**D√©marrez l'activit√© d√®s l'introduction g√©n√©rale par les formateurs termin√©e !**\n",
    "\n",
    "Parcourez ce *notebook* dans l'ordre, et n'h√©sitez pas √† solliciter les formateurs d√®s que vous avez une question.\n",
    "Aux √©tapes cl√©s de l'atelier, ces derniers utiliseront les supports de cours pour introduire certaines notions collectivement.\n",
    "Vous pouvez cependant avancer √† votre rythme en toute autonomie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation et g√©n√©ralit√©s √† propos de Spacy ‚Äî *‚è±Ô∏è 5 mn*\n",
    "Dans cette section, nous allons installer *Spacy* et comprendre quelques principes de base essentiels.\n",
    "\n",
    "En particulier, nous allons nous int√©resser aux objets repr√©sentant un mod√®le de langage et un ¬´¬†document¬†¬ª en cours d'analyse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation de Spacy\n",
    "Avant toute autre chose, nous devons installer *Spacy* !\n",
    "\n",
    "Nous avons pr√©par√© un fichier d√©crivant les paquets Python n√©cessaires √† la r√©alisation de cette activit√©.\n",
    "Si vous n'avez pas d√©j√† install√© et configur√© un environnement de travail, vous pouvez ex√©cuter la cellule suivante pour le faire.\n",
    "\n",
    "ü§ì Notez le `!` qui pr√©c√®de l'instruction : il signifie que la ligne n'est pas une instruction Python, mais une instruction shell ex√©cut√©e sur la machine qui ex√©cute ce *notebook*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour installer Spacy et les autres outils n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de la biblioth√®que\n",
    "Pour rendre disponible les objets, fonctions et autres √©l√©ments propos√©s par la biblioth√®que, nous avons besoin de la charger et de d√©finir un nom qui permet d'y faire r√©f√©rence.\n",
    "\n",
    "C'est le r√¥le de l'instruction `import`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour importer *Spacy* dans votre environnement d'ex√©cution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'objet [`Language`](https://spacy.io/api/language)\n",
    "L'objet [`Language`](https://spacy.io/api/language) sert √† repr√©senter une cha√Æne de traitements qui \n",
    "- poss√®de une repr√©sentation interne d'un langage \n",
    "- et permet de calculer un certain nombre d'√©l√©ments √† partir d'un texte ou d'autres √©l√©ments d√©j√† calcul√©s.\n",
    "\n",
    "On peut construire une nouvelle cha√Æne de traitements de plusieurs fa√ßons.\n",
    "La mani√®re la plus simple est de construire une cha√Æne de traitement **vide** (ou presque) pour le fran√ßais √† l'aide de la \"fabrique\" √† cha√Ænes de traitement [`spacy.blank(LANGAGE)`](https://spacy.io/api/top-level/#spacy.blank)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©tez et ex√©cutez la cellule suivante pour cr√©er un mod√®le de langue vide ü™π pour le fran√ßais üá´üá∑\n",
    "<details>\n",
    "<summary>Cliquez ici pour voir un indice</summary>\n",
    "\n",
    "N'h√©sitez pas √† consulter l'aide officielle de la fonction [`spacy.blank(LANGAGE)`](https://spacy.io/api/top-level/#spacy.blank) pour savoir comment l'utiliser !\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Cliquez ici pour voir la solution</summary>\n",
    "\n",
    "```python\n",
    "nlp = spacy.blank(\"fr\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy._____(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# TEACHER\n",
    "nlp = spacy.blank(\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La cha√Æne de traitements contient diff√©rents traitements appliqu√©s les uns apr√®s les autres.\n",
    "On peut afficher cette liste de traitements √† l'aide de l'attribut `pipe_names` de l'objet `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, une cha√Æne de traitement ne contient rien‚Ä¶ Sauf un *tokenizer*, d'o√π l'importance de pr√©ciser la langue !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'objet [`Doc`](https://spacy.io/api/doc)\n",
    "On obtient un objet [`Doc`](https://spacy.io/api/doc) en appliquant la cha√Æne de traitement [`Language`](https://spacy.io/api/language) √† une cha√Æne de texte.\n",
    "\n",
    "Cet objet [`Doc`](https://spacy.io/api/doc) est central pour Spacy car il va √™tre progressivement enrichi par chacun de traitements qui va venir y piocher les informations dont il a besoin en entr√©e, et y ajouter les informations qu'il a calcul√©es.\n",
    "\n",
    "Ce principe est r√©sum√© dans la figure suivante, extraire de la documentation officielle de Spacy :  \n",
    "![](https://spacy.io/images/pipeline.svg)\n",
    "\n",
    "Par exemple, le composant \"ner\" (que nous utiliserons plus tard) va venir affecter une √©tiquette (*\"label\"*) √† chacun des *tokens* du document. Il va stocker cette information dans un nouvel attribut `doc.ents` du document.\n",
    "\n",
    "L'attribut `doc.text` contient quant √† lui la liste des *tokens* extraits.\n",
    "\n",
    "<!-- More complex architecture diagram ![](https://spacy.io/images/architecture.svg) -->\n",
    "\n",
    "Pour appliquer un mod√®le de langue √† une cha√Æne de texte, il suffit d'utiliser la variable `nlp` cr√©√© comme une fonction !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©√© en traitant une chaine de caract√®res avec l'objet nlp\n",
    "doc = nlp(\"Bonjour tout le monde !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut parcourir les *tokens* extraits d'un [`Doc`](https://spacy.io/api/doc) √† l'aide d'une boucle classique en Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'objet [`Token`](https://spacy.io/api/token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©tez et ex√©cutez la cellule suivante pour afficher le contenu de chaque token du document\n",
    "Un objet [`Token`](https://spacy.io/api/token) contient un certain nombre d'[attributs](https://spacy.io/api/token#attributes) int√©ressants.\n",
    "\n",
    "Tous ces attributs ne sont pas n√©cessairement calcul√©s avec un mod√®le de langue vide, mais il est d√©j√† possible d'en observer un certain nombre.\n",
    "En particulier, vous devez utiliser l'attribut `Token.text` pour acc√©der √† sa repr√©sentation textuelle.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It√®re sur les tokens dans un Doc\n",
    "for ____ in ____:\n",
    "    print(____.____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour\n",
      "tout\n",
      "le\n",
      "monde\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# TEACHER\n",
    "# It√®re sur les tokens dans un Doc\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    # REMARQUE : on peut utiliser `print(token)` directement,\n",
    "    # mais c'est pi√®geux car l'affichage semble √™tre celui d'une cha√Æne de caract√®res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'obtenir des informations utiles √† propos des *tokens* de notre document sans m√™me avoir besoin d'utiliser un mod√®le de langue complexe.\n",
    "\n",
    "Voici un exemple que vous pouvez observer, qui tire profit des [attributs](https://spacy.io/api/token#attributes) `Token.i` (qui indique l'identifiant du *token* au sein du document parent), `Token.is_alpha`, `Token.is_punct` et `Token.like_num`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :    [0, 1, 2, 3, 4]\n",
      "Text :     ['Cela', 'co√ªte', '5', '‚Ç¨', '.']\n",
      "is_alpha : [True, True, False, False, False]\n",
      "is_punct : [False, False, False, False, True]\n",
      "like_num : [False, False, True, False, False]\n"
     ]
    }
   ],
   "source": [
    "## Autres attributs des tokens et des spans\n",
    "doc2 = nlp(\"Cela co√ªte 5 ‚Ç¨.\")\n",
    "\n",
    "print(\"Index :   \", [token.i for token in doc2])\n",
    "print(\"Text :    \", [token.text for token in doc2])\n",
    "\n",
    "print(\"is_alpha :\", [token.is_alpha for token in doc2])\n",
    "print(\"is_punct :\", [token.is_punct for token in doc2])\n",
    "print(\"like_num :\", [token.like_num for token in doc2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est √©galement possible d'acc√©der √† un token particulier, gr√¢ce √† son indice dans le document."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour afficher le premier token du document\n",
    "N'h√©sitez pas √† en afficher d'autres pour observer ce comportement.\n",
    "\n",
    "ü§ì Notez qu'il n'est pas toujours n√©cessaire d'appeler `print()` avec Jupyter : la valeur de retour de la derni√®re instruction sera affich√©e, au format texte par d√©faut ou au format HTML si une repr√©sentation plus riche est disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bonjour"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut s√©lectionner un token particulier, gr√¢ce √† son indice dans le document\n",
    "token = doc[0]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'objet [Span](https://spacy.io/api/span)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet [Span](https://spacy.io/api/span) est un autre objet utile √† conna√Ætre, qui repr√©sente une s√©quence de *tokens* contigu√´ au sein d'un document."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß <b>Essayez √† pr√©sent de s√©lectionner et afficher les <i>tokens</i> \"tout le monde\".</b>\n",
    "\n",
    "<details>\n",
    "<summary>Indices</summary>\n",
    "\n",
    "Vous pouvez utiliser les *ranges* pour s√©lectionner plusieurs √©l√©ments d'un it√©rable. Voici un exemple de la syntaxe √† utiliser :\n",
    "```python\n",
    "ma_liste = [0, 1, 2, 3]\n",
    "print(ma_liste[1:3])\n",
    "# Affiche : [1, 2]\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "On applique cette syntaxe pour s√©lectionner les tokens du rang 1 (2e token, inclus) au rang 4 (non inclus) :\n",
    "\n",
    "```python\n",
    "span = doc[1:4]\n",
    "span\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tout le monde"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On peut √©galement utiliser les \"ranges\" Python pour s√©lectionner plusieurs tokens\n",
    "span = doc[____]\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tout le monde"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEACHER\n",
    "# On peut √©galement utiliser les \"ranges\" Python pour s√©lectionner plusieurs tokens\n",
    "span = doc[1:4]\n",
    "span"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä l'instar des objets Token, ils poss√®dent √©galement des [attributs](https://spacy.io/api/span#attributes) int√©ressants, comme `Span.text` qui permet d'en obtenir une repr√©sentation textuelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tout le monde'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut √©galement acc√©der aux attributs d'un span\n",
    "span.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Reconna√Ætre des entit√©s nomm√©es avec un mod√®le existant et visualiser les r√©sultats ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons √† pr√©sent utiliser un mod√®le existant mis √† disposition par les cr√©ateurs de Spacy pour comprendre le fonctionnement d'un mod√®le de langue int√©grant un composant de reconnaissance d'entit√©s nomm√©es.\n",
    "\n",
    "Pour cela, nous allons commencer par utiliser une cha√Æne de traitement entra√Æn√©e pour le fran√ßais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix, installation et chargement du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Cherchez [dans la documentation](https://spacy.io/models/fr) un mod√®le adapt√© pour d√©marrer\n",
    "Trouvez le nom du **plus petit mod√®le contenant un composant NER** qui nous permettra de faire des premi√®res exp√©riences rapides.\n",
    "\n",
    "La taille du mod√®le est indiqu√©e dans le champ *\"Size\"*.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "On trouve 4 mod√®les :\n",
    "1. `fr_core_news_sm` : un petit mod√®le adapt√© pour nos premi√®res exp√©riences, contenant tous les composants n√©cessaires üëà *utilisez celui-ci pour mettre au point votre approche !*\n",
    "2. `fr_core_news_md` : un mod√®le de taille moyenne, contenant √©galement tous les composants de base, adapt√© √† des cas simples pour lesquels l'efficacit√© prime\n",
    "3. `fr_core_news_lg` : un mod√®le large, adapt√© au travail sur CPU, contenant tous les composants de base et offrant de bonnes performances.\n",
    "4. `fr_dep_news_trf` : un nouveau mod√®le qui devrait offrir les meilleures performances, mais ne disposant pas de composant NER pr√©-entra√Æn√© et pour lequel il faut pr√©f√©rer une ex√©cution sur GPU.\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez √† pr√©sent la commande suivante pour t√©l√©charger les fichiers du mod√®le\n",
    "Indiquez le nom du mod√®le que vous avez s√©lectionn√©.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```\n",
    "!python -m spacy download fr_core_news_sm\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download __________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from fr-core-news-sm==3.7.0) (3.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/joseph/.virtualenvs/hn-ariane-ner-tuto-2023-5IA5eVhR/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.3)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# TEACHER\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons √† pr√©sent charger ce nouveau mod√®le √† l'aide de la commande [`spacy.load(NOM_DU_MOD√àLE)`](https://spacy.io/api/top-level#spacy.load)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez la cellule suivante pour charger le mod√®le que vous venez de t√©l√©charger.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# TEACHER\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Ex√©cutez √† pr√©sent la cellule suivante pour v√©rifier que nous disposons bien de nouveau composants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premiers pas avec un mod√®le sur √©tag√®re üì¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons √† pr√©sent utiliser notre mod√®le pour extraire des informations plus int√©ressantes d'un texte, comme de l'[√©tiquetage morpho-syntaxique](https://fr.wikipedia.org/wiki/%C3%89tiquetage_morpho-syntaxique), aussi appel√© √©tiquetage grammatical, ou *POS tagging* (*part-of-speech tagging*) en anglais, pour jouer un peu avant de nous recentrer sur la reconnaissance d'entit√©s nomm√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Token    POS    Synt. dep. rel.    Synt. parent\n",
      "--------------------------------------------------\n",
      "        La    DET                det         journ√©e\n",
      "   journ√©e   NOUN              nsubj         d√©roule\n",
      "        de    ADP               case       formation\n",
      " formation   NOUN               nmod         journ√©e\n",
      "         √†    ADP               case            Lyon\n",
      "      Lyon  PROPN               nmod         journ√©e\n",
      "        se   PRON          expl:comp         d√©roule\n",
      "   d√©roule   VERB               ROOT         d√©roule\n",
      "      bien    ADV             advmod         d√©roule\n",
      "         .  PUNCT              punct         d√©roule\n"
     ]
    }
   ],
   "source": [
    "# POS tagging example\n",
    "doc = nlp(\"La journ√©e de formation √† Lyon se d√©roule bien.\")\n",
    "print(f\"{'Token':>10s}\", f\"{'POS':>6s}\", f\"{'Synt. dep. rel.':>18s}\", f\"{'Synt. parent':>15s}\")\n",
    "print(\"-\"*50)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:>10s}\", f\"{token.pos_:>6s}\", f\"{token.dep_:>18s}\", f\"{token.head.text:>15s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ì Pourquoi certains [attributs des tokens](https://spacy.io/api/token#attributes) terminent-ils par un `_` ?  \n",
    "C'est parce que la valeur de base (sans le `_`) est un identifiant (un nombre entier) qui pointe vers une case d'un grand dictionnaire d'√©l√©ments connus. C'est une fa√ßon efficace, mais peu lisible, de stocker l'information. D'o√π la variante lisible !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est √©galement possible de demander √† Spacy des explications sur un terme utilis√© √† l'aide de la fonction `spacy.explain()`.\n",
    "\n",
    "Vous pouvez modifier la cellule ci-dessous pour obtenir plus d'information sur un terme si vous le souhaitez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adverbial modifier'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"advmod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconnaissance d'entit√©s nomm√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une nouvelle phrase qui contient deux entit√©s classiques : une **personne** (√† laquelle correspondra l'√©tiquette `PER`) et un **lieu** (qui sera rep√©r√© par l'√©tiquette `LOC`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Analysons-la avec notre nouveau mod√®le !\n",
    "Ex√©cutez la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Joseph est venu en train √† Lyon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien qu'on puisse lire la valeur de l'attribut `ent_type_` de chaque objet [`Token`](https://spacy.io/api/token#attributes), il est souvent plus pratique de ne lister que les entit√©s nomm√©es d√©tect√©es dans un document. De plus, certaines entit√©s peuvent contenir plusieurs *tokens*, ce qui rend leur extraction manuelle plus d√©licate !\n",
    "\n",
    "Heureusement, l'objet [`Doc`](https://spacy.io/api/doc) dispose d'une propri√©t√© [`Doc.ents`](https://spacy.io/api/doc#ents) qui renvoie une liste d'objets [`Span`](https://spacy.io/api/span) qui repr√©sentent les positions des entit√©s et les √©tiquettes (*labels*) qui leur sont associ√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez le code de la cellule ci-dessous pour afficher le texte et le *label* de chaque entit√©\n",
    "- Utilisez les attributs `start`, `end` de chaque `Span` pour s√©lectionner le fragment de document couvert √† l'aide d'un *range* Python\n",
    "- Utiliser leur attribut `label_` pour afficher le type d'entit√© d√©tect√© sous forme textuelle\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "for ent in doc.ents:\n",
    "    print(doc[ent.start:ent.end], ent.label_)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.____:\n",
    "    print(doc[____:____], ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph PER\n",
      "Lyon LOC\n"
     ]
    }
   ],
   "source": [
    "# TEACHER\n",
    "for ent in doc.ents:\n",
    "    print(doc[ent.start:ent.end], ent.label_)\n",
    "    # print(ent, ent.label_)  # fonctionne aussi car le texte du Span est utilis√© comme valeur √† afficher\n",
    "    # print(ent.text, ent.label_)  # fonctionne √©galement / plus simple : √† privil√©gier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy dispose d'un moteur de visualisation tr√®s pratique, qui produit de tr√®s jolis r√©sultats.\n",
    "\n",
    "Il est utilisable via le module [`displacy`](https://spacy.io/universe/project/displacy) qui permet de visualiser les informations extraites d'un document, en particulier les [entit√©s nomm√©es](https://spacy.io/usage/visualizers#ent).\n",
    "\n",
    "Encore mieux, il peut √™tre [utilis√© dans un notebook](https://spacy.io/usage/visualizers#jupyter) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joseph\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " est venu en train √† \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lyon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ì Vous pouvez m√™me modifier le style d'affichage en indiquant `\"dep\"` pour afficher le graphe de d√©pendances syntaxiques de notre document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "treacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"2a6d733d03d74027b9deb540a40a13ed-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Joseph</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">est</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">venu</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">en</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">train</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">√†</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Lyon.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2a6d733d03d74027b9deb540a40a13ed-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2a6d733d03d74027b9deb540a40a13ed-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj:pass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2a6d733d03d74027b9deb540a40a13ed-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2a6d733d03d74027b9deb540a40a13ed-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux:tense</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2a6d733d03d74027b9deb540a40a13ed-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2a6d733d03d74027b9deb540a40a13ed-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2a6d733d03d74027b9deb540a40a13ed-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2a6d733d03d74027b9deb540a40a13ed-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:arg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2a6d733d03d74027b9deb540a40a13ed-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2a6d733d03d74027b9deb540a40a13ed-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2a6d733d03d74027b9deb540a40a13ed-0-5\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2a6d733d03d74027b9deb540a40a13ed-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,179.0 L1108.0,167.0 1092.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traiter les donn√©es de notre corpus d'exemple ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons √† pr√©sent utiliser notre mod√®le pour traiter les donn√©es de notre corpus et r√©aliser une premi√®re analyse qualitative superficielle des r√©sultats produits.\n",
    "\n",
    "Pour vous illustrer la proc√©dure √† suivre avec vos propres donn√©es, nous allons vous montrer comment acc√©der √† une collection de fichiers texte :\n",
    "1. si vous utilisez **Google Colab**, en utilisant le contenu d'un de vos dossiers Google Drive,\n",
    "2. si vous utilisez **votre propre machine**, en indiquant simplement le chemin vers lequel les fichiers sont stock√©s.\n",
    "\n",
    "Ces deux cas sont assez semblables, la seule diff√©rence est qu'avec Google Colab, vous utiliser une machine virtuelle distance, et que vous ne pouvez contr√¥ler cette derni√®re que par l'interm√©diaire de l'interface de Colab (un notebook am√©lior√©)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è R√©cup√©rer des fichiers int√©ressants sur votre machine\n",
    "Vous allez t√©l√©charger le jeu de donn√©es original ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù par Carmen Brando, Francesca Frontini, et Ioana Galleron.\n",
    "\n",
    "[![üì¶ Cliquez ici pour t√©l√©charger le jeu de donn√©es](https://img.shields.io/badge/%F0%9F%93%A6-Cliquez_ici_pour_t%C3%A9l%C3%A9charger_le_jeu_de_donn%C3%A9es-blue)](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/bitstream/handle/20.500.11752/OPEN-986/French_ELTEC_NER_Open_Dataset.zip) et enregistrez-le quelque-part sur votre ordinateur personnel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliser Drive pour envoyer des fichiers sur Colab\n",
    "**Si vous ex√©cutez votre *notebook* sur votre propre machine, vous pouvez passer cette partie.**\n",
    "\n",
    "√Ä pr√©sent, copiez le fichier Zip t√©l√©charg√© dans un dossier de votre choix (par exemple \"Formation Ariane\") de votre Drive.\n",
    "\n",
    "Nous sommes maintenant pr√™ts √† \"monter\" votre Drive sur la machine virtuelle que vous utilisez sur Google Colab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©tez et ex√©cutez la cellule ci-dessous et autorisez Colab √† acc√©der √† votre Drive\n",
    "Une fois cette op√©ration r√©alis√©e, votre machine virtuelle Google Colab pourra acc√©der au fichier que vous venez de d√©poser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "# COMPL√âTEZ CETTE LIGNE AVEC LE NOM DU DOSSIER DANS LEQUEL VOUS AVEZ D√âPOS√â VOTRE FICHIER\n",
    "# > just access \"/gdrive/My Drive/...\"\n",
    "FOLDER_NAME = \"Formation Ariane\"  # üëàüëàüëà\n",
    "\n",
    "# Si vous avez chang√© le nom du fichier, vous pouvez l'indiquer ici\n",
    "ZIP_FILENAME = \"French_ELTEC_NER_Open_Dataset.zip\"\n",
    "\n",
    "# On v√©rifie qu'on arrive bien √† acc√©der au fichier\n",
    "import os.path\n",
    "dataset_zip_path = f\"/gdrive/My Drive/{FOLDER_NAME}/{ZIP_FILENAME}\"\n",
    "if os.path.exists(dataset_zip_path):\n",
    "    print(\"Fichier bien trouv√© !\")\n",
    "else:\n",
    "    err_msg = f\"Erreur, le fichier n'a pas √©t√© trouv√© au chemin '{dataset_zip_path}'.\"\n",
    "    print(err_msg)\n",
    "    raise ValueError(err_msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Si vous travaillez sur votre machine personnelle, d√©-commentez, modifiez et ex√©cutez la cellule suivante\n",
    "Ceci nous servira √† indiquer :\n",
    "1. o√π est rang√© le fichier ZIP contenant le jeu de donn√©es\n",
    "2. o√π il faudra d√©compresser les fichiers qu'il contient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_zip_path = \"/home/jchazalo/Downloads/French_ELTEC_NER_Open_Dataset.zip\"\n",
    "# dataset_destination_dir = \"/home/jchazalo/tmp/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# TEACHER\n",
    "dataset_zip_path = \"/home/jchazalo/Downloads/French_ELTEC_NER_Open_Dataset.zip\"\n",
    "dataset_destination_dir = \"/home/jchazalo/tmp/datasets\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D√©compresser les fichiers\n",
    "Afin de faciliter l'acc√®s aux diff√©rents fichiers, nous allons √† pr√©sent d√©compresser les fichiers du jeu de donn√©es.\n",
    "\n",
    "Nous allons utiliser les 100 fichiers texte extraits de romans du 19e si√®cle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Ex√©cutez la cellule suivante et v√©rifiez qu'aucune erreur n'est rencontr√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jchazalo/tmp/French_ELTEC_NER_Open_Dataset.zip: OK\n",
      "Archive:  /home/jchazalo/tmp/French_ELTEC_NER_Open_Dataset.zip\n",
      "   creating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/\n",
      "   creating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/\n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a.0MBIm18ieWUH8iyy4d4RIFZKSu-FRA02802_Mirbeau.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a.GwmWhiyt0OKvDrD6b._1MxEt2K-FRA03101_Ponson.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a.JUEoYT5Jt44vnpvLAg8WSk0iVm-FRA00901_Daudet.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a.n8hDHVP39RVA3a5sKkRffFXIUO-FRA04102_Erckmann.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a_C54L4cLST4beyZLSbBM1qUuygK-FRA07001_Mendes.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a_cdO7G8FaGY5emxh2eoIs4VTvWq-FRA01302_Flaubert.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a0z.I.nFSfzECA9d.L_J7DCWOZXm-FRA05801_Mille.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a34P3V2Cg118Ym0ahNVjTy4.Ex5O-FRA04601_Bazin.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a3MNF7TUrtea7XfRiJXn6Wk0b858-FRA07201_Montagne.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a49_fmd9IHJ2wC1gsQKizy8CDYZi-FRA04001_Verne.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a5.iqH.1H1PMZS_S9ADOeQldE17q-FRA01602_GautierJ.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a5af6lkwwCShnfYUFUypljWGfaOK-FRA03601_Proust.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a5KaOu4YsuzLiiz0ROmtJI7AnhtG-FRA03702_Sand.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a6R7A7Zoq2ls3KXj7rL3NT_W4V6S-FRA00101_Adam.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a71F.BlguFo3ou6nE0MparHkmd_C-FRA02202_Gouraud.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a7hmKErzaA84WwEI1CA2P3X.8vOW-FRA02302_Greville.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a7K9yh.2wyxHG509T8Fb8wCuufFy-FRA02701_Maupassant.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a7KC5U74jME2kMN7UrkwepzFM77S-FRA05702_Maquet.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a7p9e.No7R2GKqDgEh5gBOdCRhne-FRA02203_Gouraud.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a7x9ILGFUg81t609xJAbRizBuA9K-FRA06801_Vaillant.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a8ifGWtH6jLsTLFEhsHz_ENJP11y-FRA00602_Boisgobey.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a9_JuHi9In_5VsmgTMcy5iOTqgVe-FRA01603_GautierJ.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a92twUwlsYoRjJ8euN0AMEhWGNQW-FRA04901_Dumas.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a9FSAunkcRYSVp9TeHFuqJ5cVxIS-FRA01201_Feval.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/a9P3XY5QqtvJFE.mQfM9M23M4M4m-FRA01401_Fleuriot.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aAAH8jUAa3ntArp8vRpY5ugdwvLS-FRA05201_Feuillet.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aaNd0P7.1oMqW5ygGCMZqhCCzXZe-FRA06001_Rebell.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aap1i.sUcbMOHzBFrWagaR3v9YhK-FRA06501_Gyp.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aAS0WZEtuwL67MLmDsJ3kLDhe33W-FRA04801_Corday.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aatgMri5vGFFR91ztyo2Vpp4RLJ4-FRA06901_Vignon.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aaUXY5cOU5zVcD4h6kxELupRWNKC-FRA00801_Dash.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/abAe3jd6lQovJLSTvdifwTjw14iK-FRA02303_Greville.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/abBmPweZyAxzbqSOGsC_bzk_WIuG-FRA02301_Greville.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/abRcy3SO2ZZgE3XqxWkJ2goP1D30-FRA04002_Verne.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aCBPDbOM5zaCJ.9M5n6m8l9RxWMC-FRA00601_Boisgobey.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aCQVyShyQUhBawtxZ9Eq7whm687a-FRA00401_Allais.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aDNsOWosoMcvWAOS7unI4MFI5va4-FRA03701_Sand.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aDXiGUcFvQ5eGRTuXHgEa3Jj7zQu-FRA01301_Flaubert.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/ae7pSxEUY74LSaal.Kro451VKTsq-FRA01102_Dombre.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aeA9_2pkQRJejockZFU7lsVocD.m-FRA03802_Stern.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aeb6idLObyWMnd5MtaJys1554048-FRA07401_Leblanc.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aEf9W6iinoZdPr42zuEOPWW0TMPS-FRA06201_Viel_Castel.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aEh3dvy7r5ksqjMb7fjWUtll7Zg8-FRA02101_Girardin.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aEHUPuyJPVmulQZkJ8BakruAiyDW-FRA05501_Lermina.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aEO_8KhvsTLAWv2QqX4SZ0IvY7hm-FRA06701_Uchard.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/af0u6DgsEdyVpxcbndj0QXkD5f8e-FRA02001_Gilbert.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/af67Kaz1_jylPOmtkzzx3n1glxgu-FRA02602_Malot.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/afD.eCL61SdDPWRjTudoAM2jk9DS-FRA04301_Achard.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/afvwbyoO7Lc3pbviRJ4voJDp9CFy-FRA00701_Carraud.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/afXwgQxPdGPe1nuqY7U97zHX_0YO-FRA02702_Maupassant.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aG49xz4Q9_gdA4MV1ZHTDJY7iTxu-FRA05301_Galopin.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/ag93CAXG3E9n6DWgCGjk1_8VctWG-FRA04501_Barres.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aGi__KH0QNZ1ANFO76o7qB8OvMXy-FRA06601_Peladan.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aH5qNy4.zUDTPvAx3QCcB2tmag.m-FRA01601_GautierJ.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aHqzKMns1U.VfQU61Eidq6joaKY8-FRA00501_Balzac.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aIReqXLmfG2XNR9EgVhsTm7g9Nwq-FRA01202_Feval.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/ais.zEAqAoTv6LLSHmdQZZhpotOy-FRA03704_Sand.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aIxhb2vKFLTTMf2ar6HKtpfoykbu-FRA00503_Balzac.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/ajipOWiJD9GPyfbX6PqrIe8zjSaq-FRA02901_Noailles.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aJQTThcaB8.Acw1DFtECxCK5vzt8-FRA04701_Bourget.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/ajZkDlX3ay1ok7gRkblZSAtH9zqu-FRA02603_Malot.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aKkZSKV.hejO9ZW8qYAWkHXDvJDS-FRA02401_LeRouge.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/akYsbhpc1oJq3Dehn4EHwAvA8AtO-FRA00102_Adam.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/alkA23MadVN2ldDkHGZVuuIZTrJ0-FRA03903_Stolz.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/am4zRbLRf8dk_Aq0ezymar2pUN4C-FRA03401_Reybaud.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/amC03G616xHD2JuEngguPRbuYrUq-FRA01203_Feval.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aMZR68No2EuMXD9NXGsQEtfYuquS-FRA01801_Gay.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aNCbIv5xgBC.YcGZOQCyOAqK2poS-FRA03201_Blandy.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aOjm9dSki.Gyp1bEbyCKUXvR3Z8O-FRA01902_Gaboriau.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aOZ2nsgBpU4w83XtJzB_t5XIPaMK-FRA05602_Lesueur.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/apApNAN_NnyMmYsg0izGu5fIi02q-FRA00302_Aimard.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/apJyPBI2e_FpFsK_ZetwJmImElc8-FRA01701_GautierT.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/apRNjaOFY5VhqHbJ1QCQ6BWo7QAG-FRA07601_Leroux.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aQMcTkc_8bmGK97Mddjf6.wBMR74-FRA01402_Fleuriot.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aQpnuNsLE_swa6vu75f8axlDHpaW-FRA00301_Aimard.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aradq6esreGAcnK9UnA4GpsvPaDG-FRA07301_Valgand.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aRKaO1HTqsWZrkEblhrEyMnJaTke-FRA03003_Ohnet.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aRkvpMC35BRiZLXyqejK7zHtvVTC-FRA01303_Flaubert.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/arpPvk5rH.GEmSvcIuqvNk894DvC-FRA00201_Audoux.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aRsXx.vht_It2aJeIZUc7MyU8Pdu-FRA04202_Rolland.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aS22wZszAN02LNh6VcXvYm.zrhiq-FRA05401_Kock.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aszTBqJICElzYQZ2KOuA80nSuzzO-FRA03002_Ohnet.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aTq8HnN_Pw58oRJ1gClDvWtU8mqG-FRA07501_Darien.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aTZvAK.SNhyJlS.YZjENrPlhU8wC-FRA02601_Malot.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/au1r7i2CdAMXL_66FKdlUjAeYR_S-FRA01501_France.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/au8d_r3CRvJGVeD3BSAhJnkTySTi-FRA02201_Gouraud.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/auKBnMUJlJYT0kIXYs26Mc9NvDVi-FRA05101_Eekhoud.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aUUjL2CF6wN9In1aTr_rEIT5J23e-FRA06301_Montepin.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/auZmigexkcZAtLsTQcKBSTBTmaOi-FRA02501_Loti.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aV6f6cXGmcgx5FnxTWk5NIZBGHce-FRA03302_Rattazzi.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aVsLobdZGQhwZQVfrVYk0W49xpqu-FRA05901_Moselly.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aW9XeObpMHpr3FpcV0GTZMD1ntlK-FRA01101_Dombre.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aWhjJ.i8J0rR69twVQsYk70I8umq-FRA04401_Barbusse.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aWKzYsiJtoMDIhWYTDBWtOaMQUDG-FRA01403_Fleuriot.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aWPS3B83IFWYCcPBZBSr8630HPUm-FRA06101_Sandeau.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/axs3Hj9KXAuLCtKIRi416p2YrmmC-FRA03001_Ohnet.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/aYfUdIZ4Enyib2yScShLWIV17L28-FRA00502_Balzac.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/ayHhyo58Td1JOQQPB6UAy67azg_O-FRA06401_Chandeneux.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/az2CA8KJWOb.PZ49ZQoBqRmF3SLO-FRA01002_DelarueMardrus.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations/pool/azSpIJFtoHBLzVpZM3UCSIkAoQwC-FRA07101_Blondel.txt.ann.json  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/annotations-legend.json  \n",
      "   creating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/\n",
      "   creating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/\n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a.0MBIm18ieWUH8iyy4d4RIFZKSu-FRA02802_Mirbeau.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a.GwmWhiyt0OKvDrD6b._1MxEt2K-FRA03101_Ponson.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a.JUEoYT5Jt44vnpvLAg8WSk0iVm-FRA00901_Daudet.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a.n8hDHVP39RVA3a5sKkRffFXIUO-FRA04102_Erckmann.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a_C54L4cLST4beyZLSbBM1qUuygK-FRA07001_Mendes.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a_cdO7G8FaGY5emxh2eoIs4VTvWq-FRA01302_Flaubert.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a0z.I.nFSfzECA9d.L_J7DCWOZXm-FRA05801_Mille.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a34P3V2Cg118Ym0ahNVjTy4.Ex5O-FRA04601_Bazin.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a3MNF7TUrtea7XfRiJXn6Wk0b858-FRA07201_Montagne.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a49_fmd9IHJ2wC1gsQKizy8CDYZi-FRA04001_Verne.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a5.iqH.1H1PMZS_S9ADOeQldE17q-FRA01602_GautierJ.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a5af6lkwwCShnfYUFUypljWGfaOK-FRA03601_Proust.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a5KaOu4YsuzLiiz0ROmtJI7AnhtG-FRA03702_Sand.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a6R7A7Zoq2ls3KXj7rL3NT_W4V6S-FRA00101_Adam.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a71F.BlguFo3ou6nE0MparHkmd_C-FRA02202_Gouraud.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a7hmKErzaA84WwEI1CA2P3X.8vOW-FRA02302_Greville.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a7K9yh.2wyxHG509T8Fb8wCuufFy-FRA02701_Maupassant.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a7KC5U74jME2kMN7UrkwepzFM77S-FRA05702_Maquet.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a7p9e.No7R2GKqDgEh5gBOdCRhne-FRA02203_Gouraud.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a7x9ILGFUg81t609xJAbRizBuA9K-FRA06801_Vaillant.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a8ifGWtH6jLsTLFEhsHz_ENJP11y-FRA00602_Boisgobey.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a9_JuHi9In_5VsmgTMcy5iOTqgVe-FRA01603_GautierJ.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a92twUwlsYoRjJ8euN0AMEhWGNQW-FRA04901_Dumas.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a9FSAunkcRYSVp9TeHFuqJ5cVxIS-FRA01201_Feval.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/a9P3XY5QqtvJFE.mQfM9M23M4M4m-FRA01401_Fleuriot.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aAAH8jUAa3ntArp8vRpY5ugdwvLS-FRA05201_Feuillet.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aaNd0P7.1oMqW5ygGCMZqhCCzXZe-FRA06001_Rebell.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aap1i.sUcbMOHzBFrWagaR3v9YhK-FRA06501_Gyp.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aAS0WZEtuwL67MLmDsJ3kLDhe33W-FRA04801_Corday.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aatgMri5vGFFR91ztyo2Vpp4RLJ4-FRA06901_Vignon.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aaUXY5cOU5zVcD4h6kxELupRWNKC-FRA00801_Dash.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/abAe3jd6lQovJLSTvdifwTjw14iK-FRA02303_Greville.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/abBmPweZyAxzbqSOGsC_bzk_WIuG-FRA02301_Greville.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/abRcy3SO2ZZgE3XqxWkJ2goP1D30-FRA04002_Verne.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aCBPDbOM5zaCJ.9M5n6m8l9RxWMC-FRA00601_Boisgobey.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aCQVyShyQUhBawtxZ9Eq7whm687a-FRA00401_Allais.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aDNsOWosoMcvWAOS7unI4MFI5va4-FRA03701_Sand.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aDXiGUcFvQ5eGRTuXHgEa3Jj7zQu-FRA01301_Flaubert.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/ae7pSxEUY74LSaal.Kro451VKTsq-FRA01102_Dombre.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aeA9_2pkQRJejockZFU7lsVocD.m-FRA03802_Stern.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aeb6idLObyWMnd5MtaJys1554048-FRA07401_Leblanc.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aEf9W6iinoZdPr42zuEOPWW0TMPS-FRA06201_Viel_Castel.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aEh3dvy7r5ksqjMb7fjWUtll7Zg8-FRA02101_Girardin.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aEHUPuyJPVmulQZkJ8BakruAiyDW-FRA05501_Lermina.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aEO_8KhvsTLAWv2QqX4SZ0IvY7hm-FRA06701_Uchard.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/af0u6DgsEdyVpxcbndj0QXkD5f8e-FRA02001_Gilbert.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/af67Kaz1_jylPOmtkzzx3n1glxgu-FRA02602_Malot.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/afD.eCL61SdDPWRjTudoAM2jk9DS-FRA04301_Achard.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/afvwbyoO7Lc3pbviRJ4voJDp9CFy-FRA00701_Carraud.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/afXwgQxPdGPe1nuqY7U97zHX_0YO-FRA02702_Maupassant.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aG49xz4Q9_gdA4MV1ZHTDJY7iTxu-FRA05301_Galopin.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/ag93CAXG3E9n6DWgCGjk1_8VctWG-FRA04501_Barres.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aGi__KH0QNZ1ANFO76o7qB8OvMXy-FRA06601_Peladan.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aH5qNy4.zUDTPvAx3QCcB2tmag.m-FRA01601_GautierJ.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aHqzKMns1U.VfQU61Eidq6joaKY8-FRA00501_Balzac.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aIReqXLmfG2XNR9EgVhsTm7g9Nwq-FRA01202_Feval.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/ais.zEAqAoTv6LLSHmdQZZhpotOy-FRA03704_Sand.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aIxhb2vKFLTTMf2ar6HKtpfoykbu-FRA00503_Balzac.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/ajipOWiJD9GPyfbX6PqrIe8zjSaq-FRA02901_Noailles.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aJQTThcaB8.Acw1DFtECxCK5vzt8-FRA04701_Bourget.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/ajZkDlX3ay1ok7gRkblZSAtH9zqu-FRA02603_Malot.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aKkZSKV.hejO9ZW8qYAWkHXDvJDS-FRA02401_LeRouge.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/akYsbhpc1oJq3Dehn4EHwAvA8AtO-FRA00102_Adam.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/alkA23MadVN2ldDkHGZVuuIZTrJ0-FRA03903_Stolz.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/am4zRbLRf8dk_Aq0ezymar2pUN4C-FRA03401_Reybaud.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/amC03G616xHD2JuEngguPRbuYrUq-FRA01203_Feval.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aMZR68No2EuMXD9NXGsQEtfYuquS-FRA01801_Gay.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aNCbIv5xgBC.YcGZOQCyOAqK2poS-FRA03201_Blandy.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aOjm9dSki.Gyp1bEbyCKUXvR3Z8O-FRA01902_Gaboriau.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aOZ2nsgBpU4w83XtJzB_t5XIPaMK-FRA05602_Lesueur.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/apApNAN_NnyMmYsg0izGu5fIi02q-FRA00302_Aimard.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/apJyPBI2e_FpFsK_ZetwJmImElc8-FRA01701_GautierT.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/apRNjaOFY5VhqHbJ1QCQ6BWo7QAG-FRA07601_Leroux.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aQMcTkc_8bmGK97Mddjf6.wBMR74-FRA01402_Fleuriot.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aQpnuNsLE_swa6vu75f8axlDHpaW-FRA00301_Aimard.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aradq6esreGAcnK9UnA4GpsvPaDG-FRA07301_Valgand.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aRKaO1HTqsWZrkEblhrEyMnJaTke-FRA03003_Ohnet.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aRkvpMC35BRiZLXyqejK7zHtvVTC-FRA01303_Flaubert.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/arpPvk5rH.GEmSvcIuqvNk894DvC-FRA00201_Audoux.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aRsXx.vht_It2aJeIZUc7MyU8Pdu-FRA04202_Rolland.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aS22wZszAN02LNh6VcXvYm.zrhiq-FRA05401_Kock.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aszTBqJICElzYQZ2KOuA80nSuzzO-FRA03002_Ohnet.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aTq8HnN_Pw58oRJ1gClDvWtU8mqG-FRA07501_Darien.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aTZvAK.SNhyJlS.YZjENrPlhU8wC-FRA02601_Malot.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/au1r7i2CdAMXL_66FKdlUjAeYR_S-FRA01501_France.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/au8d_r3CRvJGVeD3BSAhJnkTySTi-FRA02201_Gouraud.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/auKBnMUJlJYT0kIXYs26Mc9NvDVi-FRA05101_Eekhoud.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aUUjL2CF6wN9In1aTr_rEIT5J23e-FRA06301_Montepin.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/auZmigexkcZAtLsTQcKBSTBTmaOi-FRA02501_Loti.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aV6f6cXGmcgx5FnxTWk5NIZBGHce-FRA03302_Rattazzi.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aVsLobdZGQhwZQVfrVYk0W49xpqu-FRA05901_Moselly.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aW9XeObpMHpr3FpcV0GTZMD1ntlK-FRA01101_Dombre.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aWhjJ.i8J0rR69twVQsYk70I8umq-FRA04401_Barbusse.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aWKzYsiJtoMDIhWYTDBWtOaMQUDG-FRA01403_Fleuriot.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aWPS3B83IFWYCcPBZBSr8630HPUm-FRA06101_Sandeau.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/axs3Hj9KXAuLCtKIRi416p2YrmmC-FRA03001_Ohnet.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/aYfUdIZ4Enyib2yScShLWIV17L28-FRA00502_Balzac.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/ayHhyo58Td1JOQQPB6UAy67azg_O-FRA06401_Chandeneux.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/az2CA8KJWOb.PZ49ZQoBqRmF3SLO-FRA01002_DelarueMardrus.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/plain.html/pool/azSpIJFtoHBLzVpZM3UCSIkAoQwC-FRA07101_Blondel.txt.plain.html  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/README.md  \n",
      "   creating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/\n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00101_Adam.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00102_Adam.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00201_Audoux.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00301_Aimard.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00302_Aimard.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00401_Allais.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00501_Balzac.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00502_Balzac.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00503_Balzac.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00601_Boisgobey.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00602_Boisgobey.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00701_Carraud.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00801_Dash.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00901_Daudet.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01002_DelarueMardrus.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01101_Dombre.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01102_Dombre.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01201_Feval.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01202_Feval.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01203_Feval.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01301_Flaubert.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01302_Flaubert.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01303_Flaubert.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01401_Fleuriot.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01402_Fleuriot.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01403_Fleuriot.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01501_France.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01601_GautierJ.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01602_GautierJ.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01603_GautierJ.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01701_GautierT.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01801_Gay.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01902_Gaboriau.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02001_Gilbert.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02101_Girardin.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02201_Gouraud.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02202_Gouraud.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02203_Gouraud.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02301_Greville.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02302_Greville.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02303_Greville.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02401_LeRouge.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02501_Loti.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02601_Malot.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02602_Malot.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02603_Malot.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02701_Maupassant.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02702_Maupassant.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02802_Mirbeau.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02901_Noailles.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03001_Ohnet.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03002_Ohnet.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03003_Ohnet.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03101_Ponson.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03201_Blandy.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03302_Rattazzi.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03401_Reybaud.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03601_Proust.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03701_Sand.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03702_Sand.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03704_Sand.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03802_Stern.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03903_Stolz.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04001_Verne.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04002_Verne.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04102_Erckmann.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04202_Rolland.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04301_Achard.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04401_Barbusse.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04501_Barres.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04601_Bazin.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04701_Bourget.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04801_Corday.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04901_Dumas.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05101_Eekhoud.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05201_Feuillet.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05301_Galopin.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05401_Kock.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05501_Lermina.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05602_Lesueur.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05702_Maquet.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05801_Mille.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05901_Moselly.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06001_Rebell.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06101_Sandeau.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06201_Viel-Castel.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06301_Montepin.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06401_Chandeneux.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06501_Gyp.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06601_Peladan.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06701_Uchard.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06801_Vaillant.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06901_Vignon.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07001_Mendes.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07101_Blondel.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07201_Montagne.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07301_Valgand.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07401_Leblanc.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07501_Darien.txt  \n",
      "  inflating: /home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07601_Leroux.txt  \n",
      "total 896\n",
      "-rw-r--r-- 1 joseph joseph  2929 nov.  11  2022 tr_FRA00101_Adam.txt\n",
      "-rw-r--r-- 1 joseph joseph  2303 nov.  11  2022 tr_FRA00102_Adam.txt\n",
      "-rw-r--r-- 1 joseph joseph  4095 nov.  11  2022 tr_FRA00201_Audoux.txt\n",
      "-rw-r--r-- 1 joseph joseph  6142 nov.  11  2022 tr_FRA00301_Aimard.txt\n",
      "-rw-r--r-- 1 joseph joseph  1954 nov.  11  2022 tr_FRA00302_Aimard.txt\n",
      "-rw-r--r-- 1 joseph joseph  2023 nov.  11  2022 tr_FRA00401_Allais.txt\n",
      "-rw-r--r-- 1 joseph joseph  7188 nov.  11  2022 tr_FRA00501_Balzac.txt\n",
      "-rw-r--r-- 1 joseph joseph 29251 nov.  11  2022 tr_FRA00502_Balzac.txt\n",
      "-rw-r--r-- 1 joseph joseph 47515 nov.  11  2022 tr_FRA00503_Balzac.txt\n",
      "-rw-r--r-- 1 joseph joseph  4732 nov.  11  2022 tr_FRA00601_Boisgobey.txt\n",
      "-rw-r--r-- 1 joseph joseph  2631 nov.  11  2022 tr_FRA00602_Boisgobey.txt\n",
      "-rw-r--r-- 1 joseph joseph  5961 nov.  11  2022 tr_FRA00701_Carraud.txt\n",
      "-rw-r--r-- 1 joseph joseph  4751 nov.  11  2022 tr_FRA00801_Dash.txt\n",
      "-rw-r--r-- 1 joseph joseph  9130 nov.  11  2022 tr_FRA00901_Daudet.txt\n",
      "-rw-r--r-- 1 joseph joseph  4564 nov.  11  2022 tr_FRA01002_DelarueMardrus.txt\n",
      "-rw-r--r-- 1 joseph joseph  2014 nov.  11  2022 tr_FRA01101_Dombre.txt\n",
      "-rw-r--r-- 1 joseph joseph  3864 nov.  11  2022 tr_FRA01102_Dombre.txt\n",
      "-rw-r--r-- 1 joseph joseph  3661 nov.  11  2022 tr_FRA01201_Feval.txt\n",
      "-rw-r--r-- 1 joseph joseph  6176 nov.  11  2022 tr_FRA01202_Feval.txt\n",
      "-rw-r--r-- 1 joseph joseph  5912 nov.  11  2022 tr_FRA01203_Feval.txt\n",
      "-rw-r--r-- 1 joseph joseph  5451 nov.  11  2022 tr_FRA01301_Flaubert.txt\n",
      "-rw-r--r-- 1 joseph joseph  3752 nov.  11  2022 tr_FRA01302_Flaubert.txt\n",
      "-rw-r--r-- 1 joseph joseph 10335 nov.  11  2022 tr_FRA01303_Flaubert.txt\n",
      "-rw-r--r-- 1 joseph joseph  2707 nov.  11  2022 tr_FRA01401_Fleuriot.txt\n",
      "-rw-r--r-- 1 joseph joseph  6348 nov.  11  2022 tr_FRA01402_Fleuriot.txt\n",
      "-rw-r--r-- 1 joseph joseph  1348 nov.  11  2022 tr_FRA01403_Fleuriot.txt\n",
      "-rw-r--r-- 1 joseph joseph  5098 nov.  11  2022 tr_FRA01501_France.txt\n",
      "-rw-r--r-- 1 joseph joseph  3957 nov.  11  2022 tr_FRA01601_GautierJ.txt\n",
      "-rw-r--r-- 1 joseph joseph  3725 nov.  11  2022 tr_FRA01602_GautierJ.txt\n",
      "-rw-r--r-- 1 joseph joseph  6962 nov.  11  2022 tr_FRA01603_GautierJ.txt\n",
      "-rw-r--r-- 1 joseph joseph  5191 nov.  11  2022 tr_FRA01701_GautierT.txt\n",
      "-rw-r--r-- 1 joseph joseph  9852 nov.  11  2022 tr_FRA01801_Gay.txt\n",
      "-rw-r--r-- 1 joseph joseph  3243 nov.  11  2022 tr_FRA01902_Gaboriau.txt\n",
      "-rw-r--r-- 1 joseph joseph  3945 nov.  11  2022 tr_FRA02001_Gilbert.txt\n",
      "-rw-r--r-- 1 joseph joseph  3205 nov.  11  2022 tr_FRA02101_Girardin.txt\n",
      "-rw-r--r-- 1 joseph joseph  4179 nov.  11  2022 tr_FRA02201_Gouraud.txt\n",
      "-rw-r--r-- 1 joseph joseph  2874 nov.  11  2022 tr_FRA02202_Gouraud.txt\n",
      "-rw-r--r-- 1 joseph joseph  4262 nov.  11  2022 tr_FRA02203_Gouraud.txt\n",
      "-rw-r--r-- 1 joseph joseph  5184 nov.  11  2022 tr_FRA02301_Greville.txt\n",
      "-rw-r--r-- 1 joseph joseph  5716 nov.  11  2022 tr_FRA02302_Greville.txt\n",
      "-rw-r--r-- 1 joseph joseph  5031 nov.  11  2022 tr_FRA02303_Greville.txt\n",
      "-rw-r--r-- 1 joseph joseph  4165 nov.  11  2022 tr_FRA02401_LeRouge.txt\n",
      "-rw-r--r-- 1 joseph joseph  4856 nov.  11  2022 tr_FRA02501_Loti.txt\n",
      "-rw-r--r-- 1 joseph joseph  9893 nov.  11  2022 tr_FRA02601_Malot.txt\n",
      "-rw-r--r-- 1 joseph joseph  4030 nov.  11  2022 tr_FRA02602_Malot.txt\n",
      "-rw-r--r-- 1 joseph joseph  8414 nov.  11  2022 tr_FRA02603_Malot.txt\n",
      "-rw-r--r-- 1 joseph joseph  6676 nov.  11  2022 tr_FRA02701_Maupassant.txt\n",
      "-rw-r--r-- 1 joseph joseph  4144 nov.  11  2022 tr_FRA02702_Maupassant.txt\n",
      "-rw-r--r-- 1 joseph joseph  3666 nov.  11  2022 tr_FRA02802_Mirbeau.txt\n",
      "-rw-r--r-- 1 joseph joseph  3559 nov.  11  2022 tr_FRA02901_Noailles.txt\n",
      "-rw-r--r-- 1 joseph joseph  6178 nov.  11  2022 tr_FRA03001_Ohnet.txt\n",
      "-rw-r--r-- 1 joseph joseph  2559 nov.  11  2022 tr_FRA03002_Ohnet.txt\n",
      "-rw-r--r-- 1 joseph joseph 11146 nov.  11  2022 tr_FRA03003_Ohnet.txt\n",
      "-rw-r--r-- 1 joseph joseph  1375 nov.  11  2022 tr_FRA03101_Ponson.txt\n",
      "-rw-r--r-- 1 joseph joseph  6722 nov.  11  2022 tr_FRA03201_Blandy.txt\n",
      "-rw-r--r-- 1 joseph joseph  9507 nov.  11  2022 tr_FRA03302_Rattazzi.txt\n",
      "-rw-r--r-- 1 joseph joseph 15708 nov.  11  2022 tr_FRA03401_Reybaud.txt\n",
      "-rw-r--r-- 1 joseph joseph 35651 nov.  11  2022 tr_FRA03601_Proust.txt\n",
      "-rw-r--r-- 1 joseph joseph  7781 nov.  11  2022 tr_FRA03701_Sand.txt\n",
      "-rw-r--r-- 1 joseph joseph  5648 nov.  11  2022 tr_FRA03702_Sand.txt\n",
      "-rw-r--r-- 1 joseph joseph 18888 nov.  11  2022 tr_FRA03704_Sand.txt\n",
      "-rw-r--r-- 1 joseph joseph  4950 nov.  11  2022 tr_FRA03802_Stern.txt\n",
      "-rw-r--r-- 1 joseph joseph  6861 nov.  11  2022 tr_FRA03903_Stolz.txt\n",
      "-rw-r--r-- 1 joseph joseph  8406 nov.  11  2022 tr_FRA04001_Verne.txt\n",
      "-rw-r--r-- 1 joseph joseph  5981 nov.  11  2022 tr_FRA04002_Verne.txt\n",
      "-rw-r--r-- 1 joseph joseph  3687 nov.  11  2022 tr_FRA04102_Erckmann.txt\n",
      "-rw-r--r-- 1 joseph joseph  3306 nov.  11  2022 tr_FRA04202_Rolland.txt\n",
      "-rw-r--r-- 1 joseph joseph 11583 nov.  11  2022 tr_FRA04301_Achard.txt\n",
      "-rw-r--r-- 1 joseph joseph  3599 nov.  11  2022 tr_FRA04401_Barbusse.txt\n",
      "-rw-r--r-- 1 joseph joseph 14797 nov.  11  2022 tr_FRA04501_Barres.txt\n",
      "-rw-r--r-- 1 joseph joseph  6898 nov.  11  2022 tr_FRA04601_Bazin.txt\n",
      "-rw-r--r-- 1 joseph joseph 12178 nov.  11  2022 tr_FRA04701_Bourget.txt\n",
      "-rw-r--r-- 1 joseph joseph  3621 nov.  11  2022 tr_FRA04801_Corday.txt\n",
      "-rw-r--r-- 1 joseph joseph 25221 nov.  11  2022 tr_FRA04901_Dumas.txt\n",
      "-rw-r--r-- 1 joseph joseph  5633 nov.  11  2022 tr_FRA05101_Eekhoud.txt\n",
      "-rw-r--r-- 1 joseph joseph 18658 nov.  11  2022 tr_FRA05201_Feuillet.txt\n",
      "-rw-r--r-- 1 joseph joseph  2555 nov.  11  2022 tr_FRA05301_Galopin.txt\n",
      "-rw-r--r-- 1 joseph joseph 10359 nov.  11  2022 tr_FRA05401_Kock.txt\n",
      "-rw-r--r-- 1 joseph joseph  4189 nov.  11  2022 tr_FRA05501_Lermina.txt\n",
      "-rw-r--r-- 1 joseph joseph  4457 nov.  11  2022 tr_FRA05602_Lesueur.txt\n",
      "-rw-r--r-- 1 joseph joseph  5926 nov.  11  2022 tr_FRA05702_Maquet.txt\n",
      "-rw-r--r-- 1 joseph joseph  4150 nov.  11  2022 tr_FRA05801_Mille.txt\n",
      "-rw-r--r-- 1 joseph joseph  5428 nov.  11  2022 tr_FRA05901_Moselly.txt\n",
      "-rw-r--r-- 1 joseph joseph  6551 nov.  11  2022 tr_FRA06001_Rebell.txt\n",
      "-rw-r--r-- 1 joseph joseph 19390 nov.  11  2022 tr_FRA06101_Sandeau.txt\n",
      "-rw-r--r-- 1 joseph joseph  8990 nov.  11  2022 tr_FRA06201_Viel-Castel.txt\n",
      "-rw-r--r-- 1 joseph joseph  2379 nov.  11  2022 tr_FRA06301_Montepin.txt\n",
      "-rw-r--r-- 1 joseph joseph  3294 nov.  11  2022 tr_FRA06401_Chandeneux.txt\n",
      "-rw-r--r-- 1 joseph joseph  2578 nov.  11  2022 tr_FRA06501_Gyp.txt\n",
      "-rw-r--r-- 1 joseph joseph  4963 nov.  11  2022 tr_FRA06601_Peladan.txt\n",
      "-rw-r--r-- 1 joseph joseph  3665 nov.  11  2022 tr_FRA06701_Uchard.txt\n",
      "-rw-r--r-- 1 joseph joseph 11378 nov.  11  2022 tr_FRA06801_Vaillant.txt\n",
      "-rw-r--r-- 1 joseph joseph  5195 nov.  11  2022 tr_FRA06901_Vignon.txt\n",
      "-rw-r--r-- 1 joseph joseph 14068 nov.  11  2022 tr_FRA07001_Mendes.txt\n",
      "-rw-r--r-- 1 joseph joseph  8503 nov.  11  2022 tr_FRA07101_Blondel.txt\n",
      "-rw-r--r-- 1 joseph joseph  4192 nov.  11  2022 tr_FRA07201_Montagne.txt\n",
      "-rw-r--r-- 1 joseph joseph  4773 nov.  11  2022 tr_FRA07301_Valgand.txt\n",
      "-rw-r--r-- 1 joseph joseph  3501 nov.  11  2022 tr_FRA07401_Leblanc.txt\n",
      "-rw-r--r-- 1 joseph joseph  4713 nov.  11  2022 tr_FRA07501_Darien.txt\n",
      "-rw-r--r-- 1 joseph joseph  4194 nov.  11  2022 tr_FRA07601_Leroux.txt\n"
     ]
    }
   ],
   "source": [
    "# On commence par v√©rifier qu'on trouve bien le fichier et que son contenu n'a pas √©t√© alt√©r√©\n",
    "!echo \"7dc395be9d84ac481ff6cf0a726862b66967898986f387dd5659d554394101d6  {dataset_zip_path}\" | sha256sum -c -\n",
    "# On v√©rifie que le r√©pertoire de destination existe et on le cr√©e sinon\n",
    "!mkdir -p \"{dataset_destination_dir}\"\n",
    "# On d√©compresse le fichier dans le r√©pertoire de destination\n",
    "!unzip \"{dataset_zip_path}\" -d \"{dataset_destination_dir}\"\n",
    "# On liste le contenu du r√©pertoire de destination : on s'attend √† trouver le r√©pertoire \"French_ELTEC_NER_Open_Dataset/texts\" et √† ce qu'il contienne des fichiers texte\n",
    "!ls -lA \"{dataset_destination_dir}/French_ELTEC_NER_Open_Dataset/texts\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfait ! Nous avons des fichiers pr√™ts √† √™tre trait√©s ü¶æ !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire une liste de fichiers √† traiter\n",
    "\n",
    "Nous allons devoir charger chacun des fichiers du corpus et les passer √† notre mod√®le de langue `nlp`.\n",
    "\n",
    "Nous allons proc√©der de la fa√ßon suivante :\n",
    "\n",
    "1. nous allons construire la liste des chemins vers chacun de ces fichiers √† traiter\n",
    "2. nous allons d√©finir une fonction qui permet de charger le contenu de ces fichiers\n",
    "3. nous allons regarder les r√©sultats pour quelques fichiers\n",
    "4. finalement nous allons appeler notre mod√®le de langue avec le contenu de chacun de ces fichiers, pour stocker les entit√©s d√©tect√©es dans une grande liste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour lister les fichiers, nous allons utiliser le module Python [`glob`](https://docs.python.org/3/library/glob.html) qui permet d'obtenir une liste de fichier √† partir d'un motif.\n",
    "\n",
    "Nous allons utiliser un motif simple en indiquant un caract√®re joker `*` pour indiquer que n'importe quel caract√®re peut √™tre trouv√© √† cette position."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Corrigez l'extension des fichiers √† trouver dans la cellule suivante pour collecter la liste des fichiers texte √† traiter\n",
    "Nous allons afficher le contenu de cette liste pour v√©rifier que nous avons bien trouv√© les fichiers √† traiter.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "Remplacez le `*.json` par `*.txt`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "text_file_paths = glob(f\"{dataset_destination_dir}/French_ELTEC_NER_Open_Dataset/texts/*.json\")\n",
    "text_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03201_Blandy.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00502_Balzac.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00602_Boisgobey.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00701_Carraud.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00901_Daudet.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02301_Greville.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01201_Feval.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03903_Stolz.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01302_Flaubert.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00201_Audoux.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02603_Malot.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00601_Boisgobey.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04801_Corday.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05301_Galopin.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01102_Dombre.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04901_Dumas.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02202_Gouraud.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07301_Valgand.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00503_Balzac.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00102_Adam.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00301_Aimard.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00302_Aimard.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01202_Feval.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06601_Peladan.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04601_Bazin.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07101_Blondel.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01101_Dombre.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02401_LeRouge.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01902_Gaboriau.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05602_Lesueur.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05201_Feuillet.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06801_Vaillant.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03701_Sand.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03601_Proust.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02302_Greville.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02701_Maupassant.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02702_Maupassant.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07401_Leblanc.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05702_Maquet.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03101_Ponson.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06701_Uchard.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02001_Gilbert.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07601_Leroux.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03002_Ohnet.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01402_Fleuriot.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01602_GautierJ.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03702_Sand.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06901_Vignon.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04202_Rolland.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03302_Rattazzi.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02602_Malot.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00101_Adam.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02101_Girardin.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04301_Achard.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01801_Gay.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01301_Flaubert.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02501_Loti.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06401_Chandeneux.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02901_Noailles.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04002_Verne.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06101_Sandeau.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01701_GautierT.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00501_Balzac.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01603_GautierJ.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03001_Ohnet.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07201_Montagne.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02203_Gouraud.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06201_Viel-Castel.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05801_Mille.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01002_DelarueMardrus.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06301_Montepin.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05401_Kock.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05101_Eekhoud.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04501_Barres.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01203_Feval.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04001_Verne.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01403_Fleuriot.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04102_Erckmann.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07001_Mendes.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02303_Greville.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06001_Rebell.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01601_GautierJ.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04701_Bourget.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03003_Ohnet.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00401_Allais.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02802_Mirbeau.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA06501_Gyp.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA04401_Barbusse.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03401_Reybaud.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01303_Flaubert.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02601_Malot.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03704_Sand.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA00801_Dash.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05901_Moselly.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01501_France.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA07501_Darien.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA05501_Lermina.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA03802_Stern.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA01401_Fleuriot.txt',\n",
       " '/home/jchazalo/tmp/datasets/French_ELTEC_NER_Open_Dataset/texts/tr_FRA02201_Gouraud.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEACHER\n",
    "from glob import glob\n",
    "text_file_paths = glob(f\"{dataset_destination_dir}/French_ELTEC_NER_Open_Dataset/texts/*.txt\")\n",
    "text_file_paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©tez la cellule suivante pour v√©rifier que nous avons bien trouv√© 100 fichiers\n",
    "<details>\n",
    "<summary>Indice</summary>\n",
    "V√©rifiez que la liste des noms de fichiers contient bien 100 √©l√©ments.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "len(text_file_paths)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(text_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEACHER\n",
    "len(text_file_paths) == 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation des r√©sultats pour quelques textes\n",
    "Avant de traiter les donn√©es, nous allons v√©rifier que le mod√®le de langue produit des r√©sultats raisonnables sur quelques exemples.\n",
    "\n",
    "Si ces r√©sultats sont satisfaisants, alors nous pourrons lancer un traitement plus large, et, plus tard, mesurer la performance de fa√ßon objective sur un √©chantillon repr√©sentatif, de taille suffisante, annot√© de fa√ßon fiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vous aider, voici une fonction `load_text(filename)` qui prend en param√®tre un chemin vers un fichier texte et renvoie la (longue) cha√Æne de caract√®res de son contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filename: str) -> str:\n",
    "    \"\"\"Loads and returns the content of a text file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the text file\n",
    "\n",
    "    Returns:\n",
    "        str: String representation of the content of the file. Newlines are preserved.\n",
    "    \"\"\"\n",
    "    with open(filename, encoding=\"utf8\") as in_file:\n",
    "        return \"\".join(in_file.readlines())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©ter la cellule suivante pour traiter et visualiser les entit√©s extraites d'un texte de votre choix\n",
    "Si n√©cessaire, consultez les √©tapes pr√©c√©dentes pour retrouver les op√©rations r√©alis√©es.\n",
    "\n",
    "Rappel : la variable qui pointe vers notre mod√®le de langue s'appelle `nlp`.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "some_filename = text_file_paths[10]\n",
    "some_text = load_text(some_filename)\n",
    "some_doc = nlp(some_text)\n",
    "displacy.render(some_doc, style=\"ent\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On choisit un fichier parmi la liste des fichiers disponibles\n",
    "some_filename = text_file_paths[10]\n",
    "# On charge son contenu\n",
    "some_text = load_text(____)\n",
    "# On applique notre mod√®le de langue pour extraire des entit√©s nomm√©es (entre autres)\n",
    "some_doc = ___(____)\n",
    "# On utilise displaCy pour visualiser les entit√©s nomm√©es d√©tect√©es dans ce texte\n",
    "____.render(____, style=____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Premi√®re\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " partie<br>\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    I\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "<br>Lorsque le boh√®me \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crozat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " √©tait sorti de la mis√®re par un bon mariage qui le faisait bourgeois de la \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rue de Vaugirard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", il n'avait pas rompu avec ses anciens camarades¬†; au lieu de les fuir ou de les tenir √† distance, il avait pris plaisir √† les grouper autour de lui, tr√®s content de leur ouvrir sa maison, dont le confortable le jetait loin de la mansarde de la \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rue Ganneron\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " qu'il avait si longtemps habit√©e, et le flattait agr√©ablement.<br>Tous les mercredis, de quatre √† sept heures, il y avait r√©union chez lui √† l' \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    H√¥tel des M√©dicis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " , et c'√©tait un jour sacr√© pour lequel on se r√©servait¬†: quand une id√©e nouvelle germait dans l'esprit d'un des habitu√©s, elle √©tait caress√©e, m√ªrie, √©tudi√©e en silence, afin d'√™tre pr√©sent√©e dans sa fleur au c√©nacle. ¬´¬†J'en parlerai chez \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crozat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       "¬†¬ª¬†; les l√®vres prenaient un sourire d'esp√©rance, et l'on s'endormait tranquillement en √©coutant d√©j√† le tapage qui se ferait dans la petite salle basse de l'h√¥tel o√π \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crozat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", les mains tendues, la figure ouverte, recevait ses amis.<br>Elle √©tait aimable cette r√©ception, simple comme l'homme, cordiale de la part du mari ainsi que de celle de la femme, qui ayant √©t√© com√©dienne, avait gard√© la religion de la camaraderie. Sur une table, on trouvait des cruchons de bi√®re et des chopes¬†; √† longueur de bras, un vieux pot en gr√®s de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Beauvais\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", plein de tabac. La bi√®re √©tait bonne, le tabac sec¬†; les chopes ne restaient jamais vides¬†; on pouvait mettre ses pieds crott√©s sur les barreaux des chaises en causant librement entre hommes, et cracher sans g√™ne autour de soi.<br>Et ce n'√©tait point de niaiseries ou de futilit√©s qu'on s'entretenait, de bavardages mondains, de comm√©rages sur les amis absents, ou de potins de coteries, mais des grandes questions philosophiques, politiques, sociales, religieuses, qui r√®glent l'humanit√©.<br>\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Form√©\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " d'abord d'amis ou tout au moins de camarades qui avaient travaill√© et tra√Æn√© la mis√®re ensemble, le cercle de ces r√©unions s'√©tait peu √† peu √©largi, et si bien qu'un jour la salle de l'h√¥tel des \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    M√©dicis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " √©tait devenue une ¬´¬†parlotte¬†¬ª o√π les pr√™cheurs d'id√©es et de religions nouvelles, les penseurs, les r√©formateurs, les ap√¥tres, les politiciens, les esth√©ticiens et m√™me simplement les bavards en qu√™te d'oreilles plus ou moins complaisantes se donnaient rendez-vous¬†; venait qui voulait, et, si l'on n'entrait point l√† tout √† fait comme dans une brasserie, il suffisait d'√™tre amen√© par un habitu√© pour avoir droit √† la pipe, √† la bi√®re et √† la parole.<br>Mais, quoiqu'une certaine libert√© r√©gl√¢t l'ordre du jour de cette parlotte, on n'√©tait pas toujours certain d'arriver √† placer le discours pr√©par√© pour lequel on √©tait venu¬†; car \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crozat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " qui, selon ses propres expressions, ¬´¬†poursuivait la conciliation de la science moderne avec les religions, quelles qu'elles fussent¬†¬ª, usait et m√™me abusait de sa qualit√© de ma√Ætre de maison pour ne pas laisser les discussions s'√©carter des sujets qui le passionnaient.<br>D'ailleurs, e√ªt-il faibli en c√©dant √† des consid√©rations de bienveillance, de politesse, ou m√™me de faiblesse qui √©taient assez dans son caract√®re, que le plus assidu de ses habitu√©s, le \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    p√®re Brigard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", e√ªt montr√© de la fermet√© pour lui.<br>C'√©tait une sorte d'ap√¥tre que \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brigard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", qui s'√©tait acquis une c√©l√©brit√© en mettant en pratique dans sa vie les id√©es qu'il professait et pr√™chait¬†: \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    comte de Brigard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", il avait commenc√© par renoncer √† son titre qui le faisait vassal du respect humain et des conventions sociales¬†; -- r√©p√©titeur de droit, il e√ªt pu facilement gagner mille ou douze cents francs par mois, mais il avait arrang√© le nombre et le prix de ses le√ßons de fa√ßon que sa journ√©e ne lui rapport√¢t que dix francs, pour n'√™tre pas l'esclave de l'argent¬†; -- vivant avec une femme qu'il aimait, il avait toujours tenu, bien qu'il en e√ªt deux filles, √† rester avec elle ¬´¬†en union libre¬†¬ª et √† ne pas reconna√Ætre ses enfants, parce que la loi e√ªt affaibli les liens qui l'attachaient √† elles et amoindri ses devoirs¬†; c'√©tait la conscience qui sanctionnait ces devoirs¬†; et la nature comme la conscience faisaient de lui le plus fid√®le des maris, le meilleur, le plus affectueux, le plus tendre des p√®res. Grand, fier, portant dans sa personne et ses mani√®res l'√©l√©gance native de sa race, il s'habillait comme le commissionnaire du coin, rempla√ßant seulement le velours bleu par le velours marron, couleur moins frivole. Habitant \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Clamart\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " depuis vingt ans, il n'√©tait jamais venu √† \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " qu'√† pied, et les seules concessions qu'il accord√¢t au superflu ou au bien-√™tre consistaient l'hiver, √† faire le chemin en sabots, l'√©t√© √† porter sa veste sur son bras.<br>Ainsi organis√©, il lui fallait des disciples, et il en cherchait partout, dans les rues, o√π il retenait par le bouton les gens qu'il avait pu agripper sous les arbres du \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Luxembourg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", et le mercredi chez son ami, son vieux camarade \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crozat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Combien\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " n'en avait-il pas eu¬†! Par malheur, la plupart avaient mal tourn√©¬†; quelques-uns √©taient devenus ministres¬†; d'autres s'√©taient laiss√©s ensevelir dans les hautes places de la magistrature inamovible¬†; il y en avait qui remuaient des millions¬†; deux √©taient √† \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Noum√©a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "¬†; l'un pr√™chait dans la chaire de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Notre-Dame\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".<br>Une apr√®s-midi d'octobre, la petite salle √©tait pleine¬†; la fin des vacances avait ramen√© les habitu√©s et pour la premi√®re fois on se trouvait √† peu pr√®s en nombre pour ouvrir une discussion utile. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crozat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", pr√®s de la porte, souriait aux arrivants en donnant des poign√©es de main ¬´¬†retour de vacances¬†¬ª¬†; et \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brigard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", son chapeau de feutre mou sur la t√™te, pr√©sidait, assist√© de ses deux disciples pr√©f√©r√©s en ce moment, l'avocat \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nougar√®de\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " et le po√®te \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Glady\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " qui, eux, ne tourneraient pas mal, il en √©tait certain.<br>√Ä la v√©rit√©, pour ceux qui savaient regarder et voir, la mine bl√™me de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nougar√®de\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", ses l√®vres minces, ses yeux inquiets et une aust√©rit√© de tenue et de mani√®res qui jurait avec ses vingt-six ans, faisaient croire √† un ambitieux plut√¥t qu'√† un ap√¥tre. De m√™me, quand on savait que \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Glady\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " √©tait propri√©taire d'une belle maison √† \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " et d'immeubles en province qui lui rapportaient une centaine de mille francs de rente, on imaginait difficilement qu'il continu√¢t le \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    p√®re Brigard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".<br>Mais voir n'√©tait pas la facult√© dominante de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brigard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", c'√©tait raisonner, et le raisonnement lui disait que l'ambition ferait bient√¥t de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nougar√®de\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " un d√©put√©, comme la fortune ferait un jour de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Glady\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " un acad√©micien, et alors, bien qu'il d√©test√¢t les assembl√©es autant que les acad√©mies, ils auraient deux tribunes √©lev√©es d'o√π la bonne parole tomberait sur la foule avec plus de poids. On pouvait compter sur eux. Quand \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nougar√®de\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " avait commenc√© √† venir aux r√©unions du mercredi, il √©tait creux comme un tambour, et, s'il parlait brillamment sur n'importe quel sujet avec une faconde imperturbable, c'√©tait pour ne rien dire. Dans le premier volume de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Glady\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", on n'avait trouv√© que des mots savamment arrang√©s pour le plaisir des oreilles et des yeux. Maintenant, des id√©es soutenaient les discours de l'avocat, comme les vers du po√®te disaient quelque chose -- et ces id√©es, c'√©taient les siennes¬†; ce quelque chose, c'√©tait le parfum de son enseignement.<br>Depuis une demi-heure que les pipes br√ªlaient avec un tirage forc√©, la fum√©e ne s'√©levait plus que lourdement au plafond, et c'√©tait dans un nuage qu'on voyait \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brigard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", comme un dieu barbu, proclamant sa loi, le chapeau sur la t√™te, car, s'il avait pour r√®gle de ne jamais l'√¥ter, il le man≈ìuvrait continuellement pendant qu'il parlait, le mettant tant√¥t en avant, tant√¥t en arri√®re, √† droite, √† gauche, le relevant, l'aplatissant selon les besoins de son argumentation.<br>Il est incontestable, disait-il, que nous √©parpillons notre grande force, quand nous devrions la concentrer.<br>Il enfon√ßa son chapeau.<br>‚Äî En effet, -- il le releva -- l'heure est venue de nous affirmer comme groupe, et c'est un devoir, pour nous, puisque c'est un besoin pour l'humanit√©...<br>√Ä ce moment, un nouveau venu se glissa dans la salle, sans bruit, discr√®tement, avec l'intention manifeste de ne d√©ranger personne¬†; mais \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crozat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", qui √©tait assis pr√®s de l'entr√©e, l'arr√™ta au passage et lui serra la main¬†:<br>‚Äî \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tiens\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Saniel¬†!\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " bonjour, docteur.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER\n",
    "# On choisit un fichier parmi la liste des fichiers disponibles\n",
    "some_filename = text_file_paths[10]\n",
    "# On charge son contenu\n",
    "some_text = load_text(some_filename)\n",
    "# On applique notre mod√®le de langue pour extraire des entit√©s nomm√©es (entre autres)\n",
    "some_doc = nlp(some_text)\n",
    "# On utilise displaCy pour visualiser les entit√©s nomm√©es d√©tect√©es dans ce texte\n",
    "displacy.render(some_doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu'en pensez-vous ?**  \n",
    "‚Äî Pas si mal, √† premi√®re vue, pour un mod√®le de langue minimaliste !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traiter les donn√©es de fa√ßon massive\n",
    "\n",
    "Nous allons traiter chacun des textes et r√©cup√©rer le texte des entit√©s nomm√©es de type \"`LOC`\" pour les ajouter √† une liste.\n",
    "\n",
    "Cette liste contiendra des √©l√©ments qui nous int√©ressent (comment \"Paris\", \"Bretagne\"), ne contiendra pas quelques √©l√©ments manqu√©s, et contiendra en plus quelques √©l√©ments de bruit faussement d√©tect√©s comme des entit√©s de type `LOC`.\n",
    "\n",
    "Afin de diminuer le plus possible le temps de calcul, nous allons r√©aliser un certain nombre d'optimisations :\n",
    "\n",
    "- nous allons charger les fichiers texte √† la demande pour limiter l'utilisation de la m√©moire de la machine et commencer √† les analyser d√®s qu'ils sont charg√©s (au lieu d'attendre de tous les charger) ‚Üí utilisation d'un g√©n√©rateur Python\n",
    "- nous allons temporairement [limiter les composants actifs de notre mod√®le de langue](https://spacy.io/usage/processing-pipelines#disabling) afin de ne calculer que les √©l√©ments n√©cessaires √† la reconnaissance d'entit√©s nomm√©es ‚Üí utilisation du *context manager* [`Language.select_pipes()`](https://spacy.io/api/language#select_pipes),\n",
    "- nous allons utiliser la fonctionnalit√© de traitement √† la vol√©e de Spacy pour acc√©l√©rer les calculs et limiter l'utilisation de la m√©moire ‚Üí m√©thode [`Language.pipe()`](https://spacy.io/api/language#pipe),\n",
    "- nous allons analyser les documents au fur et √† mesure de leur analyse pour en extraire les entit√©s qui nous int√©ressent ‚Üí parcours des √©l√©ments [`Doc.ents`](https://spacy.io/api/doc#ents) et s√©lection des √©l√©ments dont l'attribut [`Span.label_`](https://spacy.io/api/span#attributes) nous convient,\n",
    "- et finalement nous ne stockerons que le texte des entit√©s nomm√©es, et non l'objet [`Span`](https://spacy.io/api/span) complet qui contient une r√©f√©rence vers tout le texte du document, afin de limiter l'utilisation m√©moire.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©ter la cellule suivante pour traiter tous les fichiers texte du corpus\n",
    "Rappel : la variable qui pointe vers notre mod√®le de langue s'appelle `nlp`.\n",
    "\n",
    "Convention : nous d√©finissons une variable `all_loc_entities: list[str]` qui contiendra le texte de toutes nos entit√©s.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "texts = (load_text(filename) for filename in text_file_paths)\n",
    "all_loc_entities: list[str] = []\n",
    "with nlp.select_pipes(enable=\"ner\"):\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"LOC\":\n",
    "                all_loc_entities.append(ent.text)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ‚Üë l'instruction ci-dessus sert √† mesurer le temps d'ex√©cution de la cellule courante\n",
    "texts = (load_text(filename) for filename in text_file_paths)  # on charge les fichiers √† la demande avec un g√©n√©rateur\n",
    "all_loc_entities: list[str] = []  # la liste qui va stocker nos r√©sultats : une simple liste d'entit√©s nomm√©es\n",
    "with nlp.____(enable=____):  # on restreint les calculs au composant \"ner\" exclusivement pour aller plus vite\n",
    "    for doc in nlp.____(texts):  # on utilise le traitement √† la vol√©e\n",
    "        for ent in doc.____:  # on parcourt les entit√©s du document\n",
    "            if ent.label_ == ____:  # on ne conserve que les entit√©s du type qui nous int√©resse\n",
    "                all_loc_entities.append(ent.____)  # on ne conserve que le texte et pas toute l'entit√© pour √©viter de garder le document en m√©moire\n",
    "# On affiche le nombre d'entit√©s nomm√©es trouv√©es\n",
    "len(all_loc_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.58 s, sys: 1.98 s, total: 9.56 s\n",
      "Wall time: 9.67 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1567"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# TEACHER\n",
    "# ‚Üë l'instruction ci-dessus sert √† mesurer le temps d'ex√©cution de la cellule courante\n",
    "texts = (load_text(filename) for filename in text_file_paths)  # on charge les fichiers √† la demande avec un g√©n√©rateur\n",
    "all_loc_entities: list[str] = []  # la liste qui va stocker nos r√©sultats : une simple liste d'entit√©s nomm√©es\n",
    "with nlp.select_pipes(enable=\"ner\"):  # on restreint les calculs au composant \"ner\" exclusivement pour aller plus vite\n",
    "    for doc in nlp.pipe(texts):  # on utilise le traitement √† la vol√©e\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"LOC\":  # on ne conserve que les entit√©s du type qui nous int√©resse\n",
    "                all_loc_entities.append(ent.text)  # on ne conserve que le texte et pas toute l'entit√© pour √©viter de garder le document en m√©moire\n",
    "# On affiche le nombre d'entit√©s nomm√©es trouv√©es\n",
    "len(all_loc_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pyr√©n√©es',\n",
       " 'canton de Montserrou',\n",
       " 'Toulouse',\n",
       " 'Suzelle',\n",
       " 'Lapeyre',\n",
       " 'soleil',\n",
       " 'Bordelaise',\n",
       " 'Italiens',\n",
       " 'Paris',\n",
       " 'Paris']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voici les premiers √©l√©ments de cette grande liste\n",
    "all_loc_entities[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è∞ O√π en √™tes-vous ?\n",
    "\n",
    "**Si vous n'avez pas le temps d'aller plus loin, ce n'est pas grave** : vous pourrez finir cette activit√© chez vous.\n",
    "üéâ Vous avez d√©j√† r√©ussi √† produire des donn√©es dans un format qui peut √™tre utile pour une analyse ult√©rieure.\n",
    "**Vous pouvez passer directement √† l'√©tape 8 d'export des donn√©es** pour avoir une vision compl√®te de la phase d'extraction de donn√©es.\n",
    "\n",
    "ü§ì Dans ce qui suit, nous allons essayer d'aller plus loin pour :\n",
    "- mettre en place un protocole d'√©valuation rigoureux nous permettant de comparer la performance de diff√©rents mod√®les (et ne pas nous contenter du mod√®le le plus l√©ger de Spacy)\n",
    "- entra√Æner un mod√®le sp√©cialis√© pour l'analyse de nos donn√©es, en v√©rifiant bien qu'il nous apporte un gain par rapport aux mod√®les existants !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluer objectivement la performance d'un mod√®le de langage ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un probl√®me de d√©tection\n",
    "\n",
    "Dans le cas de la reconnaissance d'entit√©s nomm√©es, le probl√®me est g√©n√©ralement consid√©r√© comme un probl√®me de **d√©tection**, c'est-√†-dire qu'il s'agit de rep√©rer la position et le type de donn√©es d'int√©r√™t dans un ensemble de donn√©es : texte, image, son‚Ä¶\n",
    "\n",
    "D√©tecter un √©l√©ment dans du texte revient √† identifier :\n",
    "- sa position initiale,\n",
    "- sa position finale,\n",
    "- son type.\n",
    "\n",
    "C'est exactement pour d√©crire ce type d'objet que les [`Span`](https://spacy.io/api/span) existent : leurs attributs `start`, `end` et `label_` contiennent ces informations.\n",
    "\n",
    "L'exemple ci-dessous montre comment :\n",
    "1. cr√©er un document sans en extraire aucune autre information que les *tokens* gr√¢ce √† la m√©thode [`Language.make_doc(text)`](https://spacy.io/api/Language#attributes)\n",
    "2. cr√©er un objet [`Span`](https://spacy.io/api/Span#init) avec les param√®tres utiles :\n",
    "   - les positions correspondent au caract√®re (ou token) de d√©but, et au caract√®re (ou token) apr√®s la fin, index√©es √† partir de 0\n",
    "   - la valeur de son √©tiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paris"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple 1 avec `Doc.char_span` \n",
    "# ‚Üí les positions sont correspondent √† des caract√®res !\n",
    "doc = nlp.make_doc(\"Il est parti de Paris t√¥t ce matin.\")\n",
    "span = doc.char_span(16, 21, label=\"LOC\")  \n",
    "span  # on affiche l'objet cr√©√© pour v√©rifier qu'on a saisi les bonnes valeurs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paris"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple 1 avec la construction directe d'un `Span`\n",
    "# ‚Üí c'est pratique car les positions correspondent aux tokens : plus facile √† saisir\n",
    "# ‚Üí mais il faut indiquer le document auquel on fait r√©f√©rence\n",
    "from spacy.tokens import Span\n",
    "doc = nlp.make_doc(\"Il est parti de Paris t√¥t ce matin.\")\n",
    "span = Span(doc, 4, 5, label=\"LOC\")\n",
    "span  # on affiche l'objet cr√©√© pour v√©rifier qu'on a saisi les bonnes valeurs !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bases th√©oriques\n",
    "\n",
    "Pour √©valuer objectivement la performance d'un syst√®me de traitement de donn√©es, il nous faut 3 choses :\n",
    "1. un **ensemble de couples (donn√©es d'entr√©e, donn√©e id√©ale de sortie)** ‚Äî exemple : un texte et la liste des positions et types des entit√©s nomm√©es √† d√©tecter\n",
    "2. les **donn√©es produites par le syst√®me** √† √©valuer pour chacune des donn√©es d'entr√©e de l'ensemble pr√©c√©dent\n",
    "3. une **mesure permettant de comparer** les donn√©es produites et les donn√©es attendues\n",
    "\n",
    "Nous venons de voir qu'il est possible de repr√©senter les donn√©es produites (on dit plus souvent *\"pr√©dites\"*) et les donn√©es attendues √† l'aide de d'objets [`Span`](https://spacy.io/api/Span#init).\n",
    "\n",
    "Mais **comment les comparer**, et surtout **calculer une valeur qui r√©sume la ressemblance entre deux ensembles** de positions et types pr√©dits ou attendus ?\n",
    "\n",
    "C'est tr√®s simple en r√©alit√©, car le probl√®me de d√©tection dispose de mesures standard et fiables :\n",
    "- la [**pr√©cision**](https://en.wikipedia.org/wiki/Precision_and_recall), not√©e $P$, qui mesure la quantit√© de bruit dans les r√©sultats.\n",
    "  Elle est d√©finie comme  \n",
    "  $$P = \\frac{\\text{nombre d'√©l√©ments corrects}}{\\text{nombre d'√©l√©ments d√©tect√©s}}$$\n",
    "- le [**rappel**](https://en.wikipedia.org/wiki/Precision_and_recall), not√© $R$, qui mesure la proportion d'√©l√©ments manqu√©s dans les r√©sultats.\n",
    "  Il est d√©fini comme  \n",
    "  $$R = \\frac{\\text{nombre d'√©l√©ments corrects}}{\\text{nombre d'√©l√©ments attendus}}$$\n",
    "- le [**F-score**](https://en.wikipedia.org/wiki/F-score), not√© $F$, qui synth√©tise ces deux indicateurs en calculant leur moyenne harmonique.\n",
    "  Il est d√©fini par \n",
    "  $$F = 2 \\times \\frac{P \\times R}{P + R}$$\n",
    "\n",
    "Pour chacune de ces mesures, la **valeur minimale (pire cas) est $0$**, et la **valeur maximale (d√©tection parfaite) est $1$**.\n",
    "Il est courant d'indiquer des pourcentages lorsqu'on parle de ces valeurs (il suffit de les multiplier par 100).\n",
    "\n",
    "#### üßê Bon, tout √ßa c'est bien joli, mais comment fait-on pour **savoir qu'un √©l√©ment pr√©dit correspond √† un √©l√©ment attendu** ?\n",
    "Dans notre cas, c'est tr√®s simple ! Il suffit de consid√©rer que les √©l√©ments doivent avoir **exactement la m√™me position et la m√™me √©tiquette.** Si un √©l√©ment attendu n'a aucune correspondance, alors on dit qu'il a √©t√© manqu√©, et au contraire si un √©l√©ment pr√©dit ne correspond √† aucun √©l√©ment attendu, alors on dit qu'il s'agit d'une fausse d√©tection (on dit aussi \"du bruit\").\n",
    "\n",
    "#### Mesures par classe\n",
    "En g√©n√©ral, on s'int√©resse √† un type de donn√©es particulier, aussi les outils de mesure rapportent g√©n√©ralement les mesures de pr√©cision, rappel et F-score pour chaque classe (par exemple \"LOC\"). Il s'agit du m√™me calcul que pr√©c√©demment, mais en restreignant les √©l√©ments consid√©r√©s √† un type d'√©tiquette pr√©cis.\n",
    "\n",
    "#### ü§ì Bon √† savoir : on donne de multiples noms aux donn√©es attendues :\n",
    "- donn√©es cibles (*targets*)\n",
    "- v√©rit√© terrain (*ground truth*)\n",
    "- valeurs de r√©f√©rence (*gold standard*)\n",
    "- ‚Ä¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place √† la pratique !\n",
    "Nous allons g√©n√©rer des donn√©es pr√©dites et des donn√©es de r√©f√©rence factices pour quelques fragments de texte simplistes, et nous allons calculer les diff√©rents scores pour chacun d'entre eux, de mani√®re √† comprendre le comportement de la pr√©cision, du rappel et du F-score (celui qui nous int√©resse le plus).\n",
    "\n",
    "Avant de r√©aliser des mesures, nous avons besoin de comprendre le r√¥le de deux types d'objets Spacy suppl√©mentaires :\n",
    "- [`Scorer`](https://spacy.io/api/scorer) : il est responsable de la **comparaison entre les documents de r√©f√©rence et les documents pr√©dits**. Il renvoie les mesures pour toutes les donn√©es disponibles (donc pas seulement le NER si on ne pr√©cise rien). Dans notre cas, nous utiliserons la m√©thode [`Scorer.score_spans(examples, \"ents\")`](https://spacy.io/api/scorer#score_spans) qui nous permettra de restreindre l'√©valuation aux entit√©s nomm√©es. L'utilisation typique sera la suivante :  \n",
    "    ```python\n",
    "    scorer = Scorer()\n",
    "    scores = Scorer.score_spans(examples, \"ents\")\n",
    "    ```\n",
    "- [`Example`](https://spacy.io/api/example) : on l'a vu dans l'exemple pr√©c√©dent : il faut des exemples pour appeler le `Scorer`. Ces exemples correspondent √† des **paires de documents**, qui sont bas√©s sur le **m√™me texte** : un document contenant les **valeurs pr√©dites**, et un document contenant les **valeurs de r√©f√©rence**. Pour construire un exemple, on a donc besoin de cr√©er deux documents :\n",
    "    ```python\n",
    "    text = \"Bonjour de Lyon\"\n",
    "    doc_pred = nlp(text)\n",
    "    doc_ref = nlp.make_doc(text)\n",
    "    doc_ref.ents = [Span(doc_ref, 2, 3, \"LOC\")]\n",
    "    exemple = Example(doc_pred, doc_ref)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Compl√©tez les d√©finitions des Spans ci-dessous pour constituer une v√©rit√© terrain parfaite\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 4, 5, label=\"LOC\"),\n",
    "    ]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Alice, Amsterdam)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple 1 : La r√©f√©rence et la pr√©diction coincident\n",
    "text1 = \"Alice est all√©e √† Amsterdam l'an dernier et elle a trouv√© les canaux magnifiques.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(_____, __, __, label=____),\n",
    "    Span(_____, __, __, label=____),\n",
    "    ]\n",
    "doc1_ref.ents  # On verifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Alice, Amsterdam)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER\n",
    "# Exemple 1 : La r√©f√©rence et la pr√©diction coincident\n",
    "text1 = \"Alice est all√©e √† Amsterdam l'an dernier et elle a trouv√© les canaux magnifiques.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 4, 5, label=\"LOC\"),\n",
    "    ]\n",
    "doc1_ref.ents  # On verifie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Appelez √† pr√©sent notre mod√®le de langue sur le m√™me texte pour d√©finir la pr√©diction\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "doc1_pred = nlp(text1)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Alice, Amsterdam)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1_pred = ___(_____)  # Par chance, le mod√®le de base indique les bons r√©sultats !\n",
    "doc1_pred.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Alice, Amsterdam)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER\n",
    "doc1_pred = nlp(text1)  # Par chance, le mod√®le de base indique les bons r√©sultats !\n",
    "doc1_pred.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Cr√©ez √† pr√©sent un `Example` qui contient les deux documents, et passez une __liste__ d'exemples au `Scorer`\n",
    "\n",
    "Faites attention √† l'ordre des param√®tres pour construire un [`Example`](https://spacy.io/api/example#init) : le premier est la pr√©diction, le second la r√©f√©rence.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "example = Example(doc1_pred, doc1_ref)\n",
    "scorer = Scorer()\n",
    "score = scorer.score_spans([example], attr=\"ents\")\n",
    "score\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_p': 1.0,\n",
       " 'ents_r': 1.0,\n",
       " 'ents_f': 1.0,\n",
       " 'ents_per_type': {'PER': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       "  'LOC': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = Example(_____, _____)\n",
    "scorer = Scorer()\n",
    "score = scorer.score_spans(_____, attr=\"ents\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_p': 1.0,\n",
       " 'ents_r': 1.0,\n",
       " 'ents_f': 1.0,\n",
       " 'ents_per_type': {'PER': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       "  'LOC': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER\n",
    "example = Example(doc1_pred, doc1_ref)\n",
    "scorer = Scorer()\n",
    "score = scorer.score_spans([example], attr=\"ents\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit v√©rifier que tous les indicateurs sont √† 1 (la valeur maximale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä pr√©sent, nous pouvons adapter l'exemple pr√©c√©dent pour tester les cas suivants et observer l'impact sur les diff√©rents scores :\n",
    "- une entit√© attendue est manqu√©e\n",
    "- une entit√© est pr√©dite par erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Adaptez le code suivant pour tester les cas que nous venons de mentionner\n",
    "\n",
    "Nous allons simuler des d√©tections erron√©es plut√¥t que d'essayer de pi√©ger le mod√®le de langue.\n",
    "\n",
    "Observez l'impact des oublis et des fausses d√©tection sur la pr√©cision, le rappel et le F-score.\n",
    "\n",
    "<details>\n",
    "<summary>Solution cas 1</summary>\n",
    "\n",
    "```python\n",
    "text1 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc1_ref.ents  # On verifie\n",
    "doc1_pred = nlp.make_doc(text1)\n",
    "doc1_pred.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),  # Il manque Alex\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "example1 = Example(doc1_pred, doc1_ref)\n",
    "scorer.score_spans([example1], attr=\"ents\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary>Solution cas 2</summary>\n",
    "\n",
    "```python\n",
    "text2 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc2_ref = nlp.make_doc(text2)\n",
    "doc2_ref.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc2_ref.ents  # On verifie\n",
    "doc2_pred = nlp.make_doc(text2)\n",
    "doc2_pred.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    Span(doc2_ref, 10, 11, label=\"LOC\"),  # \"dernier\" d√©tect√© par erreur\n",
    "    ]\n",
    "example2 = Example(doc2_pred, doc2_ref)\n",
    "scorer.score_spans([example2], attr=\"ents\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_p': 1.0,\n",
       " 'ents_r': 0.6666666666666666,\n",
       " 'ents_f': 0.8,\n",
       " 'ents_per_type': {'PER': {'p': 1.0, 'r': 0.5, 'f': 0.6666666666666666},\n",
       "  'LOC': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAS 1 : UNE ENTIT√â ATTENDUE EST MANQU√âE\n",
    "text1 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "# doc1_ref.ents  # On verifie\n",
    "doc1_pred = nlp.make_doc(text1)\n",
    "doc1_pred.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "example1 = Example(doc1_pred, doc1_ref)\n",
    "scorer.score_spans([example1], attr=\"ents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_p': 1.0,\n",
       " 'ents_r': 0.6666666666666666,\n",
       " 'ents_f': 0.8,\n",
       " 'ents_per_type': {'PER': {'p': 1.0, 'r': 0.5, 'f': 0.6666666666666666},\n",
       "  'LOC': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER\n",
    "# CAS 1 : UNE ENTIT√â ATTENDUE EST MANQU√âE\n",
    "text1 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc1_ref.ents  # On verifie\n",
    "doc1_pred = nlp.make_doc(text1)\n",
    "doc1_pred.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),  # Il manque Alex\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "example1 = Example(doc1_pred, doc1_ref)\n",
    "scorer.score_spans([example1], attr=\"ents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_p': 0.75,\n",
       " 'ents_r': 1.0,\n",
       " 'ents_f': 0.8571428571428571,\n",
       " 'ents_per_type': {'PER': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       "  'LOC': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAS 2 : UNE ENTIT√â EST PR√âDITE PAR ERREUR\n",
    "text2 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc2_ref = nlp.make_doc(text2)\n",
    "doc2_ref.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "# doc2_ref.ents  # On verifie\n",
    "doc2_pred = nlp.make_doc(text2)\n",
    "doc2_pred.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "example2 = Example(doc2_pred, doc2_ref)\n",
    "scorer.score_spans([example2], attr=\"ents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_p': 0.75,\n",
       " 'ents_r': 1.0,\n",
       " 'ents_f': 0.8571428571428571,\n",
       " 'ents_per_type': {'PER': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       "  'LOC': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER\n",
    "# CAS 2 : UNE ENTIT√â EST PR√âDITE PAR ERREUR\n",
    "text2 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc2_ref = nlp.make_doc(text2)\n",
    "doc2_ref.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc2_ref.ents  # On verifie\n",
    "doc2_pred = nlp.make_doc(text2)\n",
    "doc2_pred.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    Span(doc2_ref, 10, 11, label=\"LOC\"),  # \"dernier\" d√©tect√© par erreur\n",
    "    ]\n",
    "example2 = Example(doc2_pred, doc2_ref)\n",
    "scorer.score_spans([example2], attr=\"ents\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Annoter un jeu de donn√©es complet : aper√ßu du probl√®me ‚Äî *‚è±Ô∏è 5 mn*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En g√©n√©ral, on a besoin de constituer et d'annoter un nouveau de donn√©es pour (au moins) une des deux raisons suivantes :\n",
    "1. Pour **√©valuer** rigoureusement la performance d'un ou plusieurs syst√®mes de traitement de donn√©es. Dans ce cas, on parle g√©n√©ralement de **jeu de test**, de **d√©veloppement** ou de **validation** (notions voisines sans √™tre exactement √©quivalentes). Il faut des donn√©es d'une quantit√© et d'une vari√©t√© suffisantes pour que les r√©sultats soient significatifs. Ce jeu de donn√©es ne peut pas contenir de donn√©es vues pendant l'entra√Ænement.\n",
    "2. Pour **entra√Æner** ou **sp√©cialiser** un mod√®le de langue bas√© sur une approche statistique. Dans ce cas, on parle de **jeu d'entra√Ænement** (*\"train set\"*). On a g√©n√©ralement besoin d'une quantit√© de donn√©es plus importante pour permettre la stabilisation des param√®tres statistiques du mod√®le. Ici aussi, ces donn√©es doivent √™tre suffisamment vari√©es pour permettre de capturer les subtilit√©s des donn√©es √† traiter, et assez repr√©sentatives pour capturer en priorit√© les g√©n√©ralit√©s.\n",
    "\n",
    "\n",
    "Dans les 2 cas, comme nous n'avons vu dans la section pr√©c√©dente, il faut pr√©parer :\n",
    "- des exemples de donn√©es d'entr√©e pour le syst√®me (√©chantillons de textes)\n",
    "- les sorties parfaites attendues pour ces donn√©es (dans le cas du NER, liste des entit√©s ‚Äî avec position et √©tiquette ‚Äî √† extraire).\n",
    "\n",
    "\n",
    "La fa√ßon la plus √©l√©mentaire de r√©aliser ce travail peut se d√©composer en :\n",
    "1. **identifier** un groupe de textes √† √©tiqueter,\n",
    "2. **importer** les textes dans un outil d'annotation et les **annoter**,\n",
    "3. **exporter** les donn√©es et les **convertir** dans un format adapt√©.\n",
    "\n",
    "### Quelques outils d'annotation\n",
    "- [ner-annotator](https://tecoholic.github.io/ner-annotator) : un petit outil libre et gratuit, tr√®s simple, qui a le m√©rite d'√™tre rapide √† utiliser pour illustrer la d√©marche.\n",
    "- [Brat](http://brat.nlplab.org/) : un outil libre et gratuit, plus complet, mais qui n√©cessite une installation.\n",
    "- [LabelStudio](https://labelstud.io/) : un outil autre libre et gratuit, assez complet, qui n√©cessite une installation mais peut aussi √™tre utilis√© en ligne.\n",
    "- [UniversalDataTool](https://universaldatatool.com) : un outil autre libre et gratuit, assez complet, qui n√©cessite une installation mais peut aussi √™tre utilis√© en ligne, et qui offre des fonctionnalit√©s de collaboration.\n",
    "- [TagTog](https://www.tagtog.com/) : un outil en ligne payant, offrant de nombreuses fonctionnalit√©s, mais qui ne semble plus trop maintenu.\n",
    "- [Prodigy](https://prodi.gy/) : un outil en ligne, payant, d√©velopp√© par les cr√©ateurs de spaCy, qui offre de nombreuses fonctionnalit√©s."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Place √† la pratique !\n",
    "\n",
    "Pour appr√©hender rapidement les joies et peines de l'annotation, nous vous proposons d'annoter (au moins partiellement) un texte choisi au hasard parmi ceux du corpus.\n",
    "\n",
    "Vous pouvez soit s√©lectionner un des textes du corpus sur votre ordinateur, soit en t√©l√©charger un au hasard depuis la machine virtuelle Colab en ex√©cutant la cellule ci-dessous.\n",
    "\n",
    "Ensuite, consultez la page <https://tecoholic.github.io/ner-annotator/> pour r√©aliser une annotation rapide :\n",
    "1. d√©posez votre fichier texte,\n",
    "2. configurer les tags √† utiliser,\n",
    "3. annotez le texte,\n",
    "4. t√©l√©chargez vos annotations au format JSON, qui pourront facilement √™tre [converties au format spaCy](https://spacy.io/api/data-formats#json-input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a file from the VM\n",
    "from google.colab import files\n",
    "files.download(text_file_paths|10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon √† savoir : il existe plusieurs techniques pour pr√©m√¢cher le travail :\n",
    "- utiliser un premier mod√®le de langue qui donne des r√©sultats moyens, mais qui permet toutefois de gagner du temps (ce n'est pas toujours le cas)\n",
    "- chercher des motifs particuliers en utilisant un [`Matcher`](https://spacy.io/api/matcher) ; c'est rapide mais il faut avoir une bonne connaissance de notre corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ì Pour aller plus loin\n",
    "Voici quelques questions qu'on se pose g√©n√©ralement lorsqu'on d√©marre une campagne d'annotation.\n",
    "- Quelles √©tiquettes/labels utiliser ?\n",
    "- Quelles r√®gles suivre, comment g√©rer les ambigu√Øt√©s ?\n",
    "- Comment distribuer le travail entre plusieurs annotateurs ? Comment assurer la coh√©rence entre le travail des diff√©rents annotateurs ?\n",
    "- Comment diffuser notre travail, le partager, quelle licence utiliser ?\n",
    "\n",
    "Toutes ces questions m√©riteraient un atelier d√©di√©‚Ä¶\n",
    "\n",
    "*Sachez juste qu'il faut essayer de d√©marrer peu de donn√©es et valider l'int√©gralit√© du processus avant d'investir massivement dans un effort d'annotation.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entra√Æner un mod√®le sp√©cialis√© et comparer sa performance ‚Äî *‚è±Ô∏è 10 mn*\n",
    "\n",
    "train/test split : load donn√©es d√©j√† pr√©par√©es (donner lien vers le code de pr√©paration (nb 10 et 23) pour les curieux‚ãÖses) ‚Äî dire que c'est la pr√©paration des donn√©es qui a pris le plus de temps, alors m√™me qu'elles avaient d√©j√† √©t√© packag√©es !\n",
    "\n",
    "eval fr-sm, fr-md, fr-lg (pas de NER pour la version transformer)\n",
    "\n",
    "train la version fr-sm pour avoir le temps de regarder les r√©sultats\n",
    "\n",
    "reload best model\n",
    "\n",
    "eval best trained model\n",
    "\n",
    "\n",
    "comparer et conclure\n",
    "\n",
    "(exercice : utiliser le meilleur mod√®le pour traiter toutes les donn√©es)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export des donn√©es pour une utilisation ult√©rieure ‚Äî *‚è±Ô∏è 2 mn*\n",
    "\n",
    "Nous allons stocker les donn√©es produites dans un fichier JSON facile √† r√©utiliser et convertir.\n",
    "\n",
    "Nous allons sauvegarder ce fichier dans votre Drive ou √† l'emplacement que vous indiquerez ci-apr√®s.\n",
    "\n",
    "Nous allons √©galement vous montrer comment t√©l√©charger directement le fichier vers votre machine locale si vous utilisez Google Colab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez les cellules suivantes, en modifiant le chemin vers l'emplacement de sauvegarde du fichier si n√©cessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHEMIN VERS LE FICHIER DE SAUVEGARDE\n",
    "PATH_TO_SAVE_FILE = f\"/gdrive/My Drive/{FOLDER_NAME}/en_french_eltec_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# TEACHER\n",
    "PATH_TO_SAVE_FILE = f\"/home/jchazalo/tmp/entites_loc_french_eltec_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition d'une fonction de sauvegarde\n",
    "import json\n",
    "def save_my_entities(data: list[str], filename: str):\n",
    "    with open(filename, mode='w', encoding=\"utf8\") as out_file:\n",
    "        json.dump(data, out_file, indent=0)\n",
    "    print(f\"Your data was successfully save to '{filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved your data to '/home/jchazalo/tmp/entites_loc_french_eltec_dataset.json'!\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du fichier\n",
    "save_my_entities(all_loc_entities, PATH_TO_SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©chargement direct du fichier depuis la VM Colab\n",
    "files.download(PATH_TO_SAVE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ C'est tout pour cette fois !\n",
    "\n",
    "TODO reformuler\n",
    "ce qui n'a pas √©t√© abord√© ici :\n",
    "\n",
    "la s√©lection des donn√©es du corpus\n",
    "la conversion des donn√©es vers et depuis la plateforme d'annotation\n",
    "la pr√©paration des donn√©es d'entra√Ænement et d'√©valuation\n",
    "les matchers\n",
    "\n",
    "Nous avons r√©alis√© toutes ces op√©rations pour la pr√©paration de cette activit√©, et vous pourrez regarder ces notebooks si vous le souhaitez, afin de disposer d'exemples de code √† r√©utiliser."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hn-ariane-ner-tuto-2023-PwR_0BG5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
