{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiation √† la üîé reconnaissance d'entit√©s nomm√©es üîç avec [spaCy](https://spacy.io/)\n",
    "\n",
    "<p style=\"font-size:small;font-style:italic\">filename: \"intro-ner-spacy-student.ipynb\" ‚Äî generation_timestamp: 2023-10-13_170413 ‚Äî source_commit: 6884f66c9f265b2d76ac0c83107aa6c03b0653b5</p>\n",
    "<p style=\"font-size:small;\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dct=\"http://purl.org/dc/terms/\"><a property=\"dct:title\" rel=\"cc:attributionURL\" href=\"https://github.com/jchazalon/hn-ariane-ner-tuto-2023 \">Tous les supports de cette activit√©</a> cr√©√©s par <a rel=\"cc:attributionURL dct:creator\" property=\"cc:attributionName\" href=\"https://jchazalon.github.io\">Joseph Chazalon</a> sont distribu√©s selon les termes de la licence Creative Commons <a href=\"http://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1\" target=\"_blank\" rel=\"license noopener noreferrer\" style=\"display:inline-block;\">Attribution-ShareAlike 4.0 International<img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\"></a></p> \n",
    "\n",
    "[![](https://img.shields.io/badge/Google_%20_Colab-Cliquez_ici_pour_√©diter_ce_notebook-blue?logo=googlecolab)](https://colab.research.google.com/github/jchazalon/hn-ariane-ner-tuto-2023/blob/main/intro-ner-spacy-student.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**üëã Bonjour !**\n",
    "\n",
    "Cette activit√© a pour objectif de vous apprendre √† utiliser la biblioth√®que [spaCy](https://spacy.io/) et de mettre en place un projet de reconnaissance d'entit√©s nomm√©es (*[Named entities recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)*, ou *NER* en anglais).\n",
    "\n",
    "Au travers d'exercices et d'observations simples qui vous permettront d'envisager la cha√Æne de traitement de donn√©es dans son ensemble, vous allez prendre en main quelques d'outils essentiels.\n",
    "Ainsi, vous devriez pouvoir r√©appliquer cette approche sur des donn√©es de votre choix, apr√®s cet atelier, en toute autonomie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Contenu de cette activit√©"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction ‚Äî *‚è±Ô∏è 5 mn*\n",
    "2. Installation et g√©n√©ralit√©s √† propos de spaCy ‚Äî *‚è±Ô∏è 5 mn*\n",
    "3. Reconna√Ætre des entit√©s nomm√©es avec un mod√®le existant et visualiser les r√©sultats ‚Äî *‚è±Ô∏è 5 mn*\n",
    "4. Traiter les donn√©es de notre corpus d'exemple ‚Äî *‚è±Ô∏è 5 mn*\n",
    "5. √âvaluer objectivement la performance d'un mod√®le de langage ‚Äî *‚è±Ô∏è 5 mn*\n",
    "6. Annoter un jeu de donn√©es complet : aper√ßu du probl√®me ‚Äî *‚è±Ô∏è 5 mn*\n",
    "7. Entra√Æner un mod√®le sp√©cialis√© et comparer sa performance ‚Äî *‚è±Ô∏è 10 mn*\n",
    "8. Export des donn√©es pour une utilisation ult√©rieure ‚Äî *‚è±Ô∏è 2 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üó∫Ô∏è Symboles utilis√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Au cours de cette activit√©, vous aurez des actions √† r√©aliser.\n",
    "  Celles-ci sont indiqu√©es par les symboles üöß, üèóÔ∏è, üõ†Ô∏è, üë∑.\n",
    "- Certains √©l√©ments n√©cessitant votre attention sont indiqu√©s par des symboles comme üö®, ‚ö†Ô∏è, üëâ.\n",
    "- Et finalement, certains √©l√©ments sont indiqu√©s pour vous permettre de prolonger cette activit√© en dehors du cr√©neau r√©serv√© et sont indiqu√©s par le symbole ü§ì.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources et licence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cet atelier est largement tir√© du cours ‚Äú[NLP avanc√© avec spaCy](https://course.spacy.io/fr)‚Äù r√©alis√© par [Ines Montani](https://twitter.com/_inesmontani) (cr√©atrice de [spaCy](https://spacy.io/)) sous [licence MIT](https://www.tldrlegal.com/license/mit-license).\n",
    "Cette licence nous autorise √† reprendre, modifier et diffuser son contenu tant que nous indiquons la licence originale :\n",
    "\n",
    ">The MIT License (MIT)\n",
    ">Copyright (C) 2019 Ines Montani\n",
    ">Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\n",
    "Les donn√©es de cet atelier sont adapt√©es du ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù par Carmen Brando, Francesca Frontini, et Ioana Galleron sous licence [Creative Commons - Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/). \n",
    "\n",
    "> Brando, Carmen; Frontini, Francesca and Galleron, Ioana, 2022, French ELTEC NER Open Dataset, ILC-CNR for CLARIN-IT repository hosted at Institute for Computational Linguistics \"A. Zampolli\", National Research Council, in Pisa, [http://hdl.handle.net/20.500.11752/OPEN-986](http://hdl.handle.net/20.500.11752/OPEN-986).\n",
    "\n",
    "Ce cours et les donn√©es associ√©es sont sous licence [Creative Commons - Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/).\n",
    "Pour citer ce travail, merci d'indiquer :\n",
    "\n",
    "> Consortium HumaNum Ariane, Joseph Chazalon, Atelier d'initiation √† la reconnaissance d'entit√©s nomm√©es avec spaCy, en ligne : <https://github.com/jchazalon/hn-ariane-ner-tuto-2023>, 9 novembre 2023, Lyon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ C'est parti !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le lien vers la pr√©sentation : <https://docs.google.com/presentation/d/1_RycfOOeQo8XZNojsx7SzaSDyhepj-8n8w7xMpf9UGI/edit>\n",
    "\n",
    "Vous pouvez aussi acc√©der √† tous les fichiers de cette activit√© (pour les t√©l√©charger par exemple) sur GitHub : <https://github.com/jchazalon/hn-ariane-ner-tuto-2023>\n",
    "\n",
    "**D√©marrez l'activit√© d√®s l'introduction g√©n√©rale par les formateurs termin√©e !**\n",
    "\n",
    "Parcourez ce *notebook* dans l'ordre, et n'h√©sitez pas √† solliciter les formateurs d√®s que vous avez une question.\n",
    "Aux √©tapes cl√©s de l'atelier, ces derniers utiliseront les supports de cours pour introduire certaines notions collectivement.\n",
    "Vous pouvez cependant avancer √† votre rythme en toute autonomie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation et g√©n√©ralit√©s √† propos de spaCy ‚Äî *‚è±Ô∏è 5 mn*\n",
    "Dans cette section, nous allons installer *spaCy* et comprendre quelques principes de base essentiels.\n",
    "\n",
    "En particulier, nous allons nous int√©resser aux objets repr√©sentant un mod√®le de langage et un ¬´¬†document¬†¬ª en cours d'analyse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Installation de spaCy\n",
    "Avant toute autre chose, nous devons installer *spaCy* !\n",
    "\n",
    "Nous avons pr√©par√© un fichier d√©crivant les paquets Python n√©cessaires √† la r√©alisation de cette activit√©.\n",
    "Si vous n'avez pas d√©j√† install√© et configur√© un environnement de travail, vous pouvez ex√©cuter la cellule suivante pour le faire.\n",
    "\n",
    "ü§ì Notez le `!` qui pr√©c√®de l'instruction : il signifie que la ligne n'est pas une instruction Python, mais une instruction shell ex√©cut√©e sur la machine qui ex√©cute ce *notebook*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour installer spaCy et les autres outils n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/jchazalon/hn-ariane-ner-tuto-2023/main/requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Import de la biblioth√®que\n",
    "Pour rendre disponible les objets, fonctions et autres √©l√©ments propos√©s par la biblioth√®que, nous avons besoin de la charger et de d√©finir un nom qui permet d'y faire r√©f√©rence.\n",
    "\n",
    "C'est le r√¥le de l'instruction `import`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour importer *spaCy* dans votre environnement d'ex√©cution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 L'objet [`Language`](https://spacy.io/api/language)\n",
    "L'objet [`Language`](https://spacy.io/api/language) sert √† repr√©senter une cha√Æne de traitements qui \n",
    "- poss√®de une repr√©sentation interne d'un langage \n",
    "- et permet de calculer un certain nombre d'√©l√©ments √† partir d'un texte ou d'autres √©l√©ments d√©j√† calcul√©s.\n",
    "\n",
    "On peut construire une nouvelle cha√Æne de traitements de plusieurs fa√ßons.\n",
    "La mani√®re la plus simple est de construire une cha√Æne de traitement **vide** (ou presque) pour le fran√ßais √† l'aide de la \"fabrique\" √† cha√Ænes de traitement [`spacy.blank(LANGAGE)`](https://spacy.io/api/top-level/#spacy.blank)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©tez et ex√©cutez la cellule suivante pour cr√©er un mod√®le de langue vide ü™π pour le fran√ßais üá´üá∑\n",
    "<details>\n",
    "<summary>Cliquez ici pour voir un indice</summary>\n",
    "\n",
    "N'h√©sitez pas √† consulter l'aide officielle de la fonction [`spacy.blank(LANGAGE)`](https://spacy.io/api/top-level/#spacy.blank) pour savoir comment l'utiliser !\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Cliquez ici pour voir la solution</summary>\n",
    "\n",
    "```python\n",
    "nlp = spacy.blank(\"fr\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy._____(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La cha√Æne de traitements contient diff√©rents traitements appliqu√©s les uns apr√®s les autres.\n",
    "On peut afficher cette liste de traitements √† l'aide de l'attribut `pipe_names` de l'objet `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, une cha√Æne de traitement ne contient rien‚Ä¶ Sauf un *tokenizer*, d'o√π l'importance de pr√©ciser la langue !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 L'objet [`Doc`](https://spacy.io/api/doc)\n",
    "On obtient un objet [`Doc`](https://spacy.io/api/doc) en appliquant la cha√Æne de traitement [`Language`](https://spacy.io/api/language) √† une cha√Æne de texte.\n",
    "\n",
    "Cet objet [`Doc`](https://spacy.io/api/doc) est central pour spaCy car il va √™tre progressivement enrichi par chacun de traitements qui va venir y piocher les informations dont il a besoin en entr√©e, et y ajouter les informations qu'il a calcul√©es.\n",
    "\n",
    "Ce principe est r√©sum√© dans la figure suivante, extraire de la documentation officielle de spaCy :  \n",
    "![](https://spacy.io/images/pipeline.svg)\n",
    "\n",
    "Par exemple, le composant \"ner\" (que nous utiliserons plus tard) va venir affecter une √©tiquette (*\"label\"*) √† chacun des *tokens* du document. Il va stocker cette information dans un nouvel attribut `doc.ents` du document.\n",
    "\n",
    "L'attribut `doc.text` contient quant √† lui la liste des *tokens* extraits.\n",
    "\n",
    "<!-- More complex architecture diagram ![](https://spacy.io/images/architecture.svg) -->\n",
    "\n",
    "Pour appliquer un mod√®le de langue √† une cha√Æne de texte, il suffit d'utiliser la variable `nlp` cr√©√© comme une fonction !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©√© en traitant une chaine de caract√®res avec l'objet nlp\n",
    "doc = nlp(\"Bonjour tout le monde !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut parcourir les *tokens* extraits d'un [`Doc`](https://spacy.io/api/doc) √† l'aide d'une boucle classique en Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 L'objet [`Token`](https://spacy.io/api/token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©tez et ex√©cutez la cellule suivante pour afficher le contenu de chaque token du document\n",
    "Un objet [`Token`](https://spacy.io/api/token) contient un certain nombre d'[attributs](https://spacy.io/api/token#attributes) int√©ressants.\n",
    "\n",
    "Tous ces attributs ne sont pas n√©cessairement calcul√©s avec un mod√®le de langue vide, mais il est d√©j√† possible d'en observer un certain nombre.\n",
    "En particulier, vous devez utiliser l'attribut `Token.text` pour acc√©der √† sa repr√©sentation textuelle.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It√®re sur les tokens dans un Doc\n",
    "for ____ in ____:\n",
    "    print(____.____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'obtenir des informations utiles √† propos des *tokens* de notre document sans m√™me avoir besoin d'utiliser un mod√®le de langue complexe.\n",
    "\n",
    "Voici un exemple que vous pouvez observer, qui tire profit des [attributs](https://spacy.io/api/token#attributes) `Token.i` (qui indique l'identifiant du *token* au sein du document parent), `Token.is_alpha`, `Token.is_punct` et `Token.like_num`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autres attributs des tokens et des spans\n",
    "doc2 = nlp(\"Cela co√ªte 5 ‚Ç¨.\")\n",
    "\n",
    "print(\"Index :   \", [token.i for token in doc2])\n",
    "print(\"Text :    \", [token.text for token in doc2])\n",
    "\n",
    "print(\"is_alpha :\", [token.is_alpha for token in doc2])\n",
    "print(\"is_punct :\", [token.is_punct for token in doc2])\n",
    "print(\"like_num :\", [token.like_num for token in doc2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est √©galement possible d'acc√©der √† un token particulier, gr√¢ce √† son indice dans le document."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour afficher le premier token du document\n",
    "N'h√©sitez pas √† en afficher d'autres pour observer ce comportement.\n",
    "\n",
    "ü§ì Notez qu'il n'est pas toujours n√©cessaire d'appeler `print()` avec Jupyter : la valeur de retour de la derni√®re instruction sera affich√©e, au format texte par d√©faut ou au format HTML si une repr√©sentation plus riche est disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut s√©lectionner un token particulier, gr√¢ce √† son indice dans le document\n",
    "token = doc[0]\n",
    "token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 L'objet [Span](https://spacy.io/api/span)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet [Span](https://spacy.io/api/span) est un autre objet utile √† conna√Ætre, qui repr√©sente une s√©quence de *tokens* contigu√´ au sein d'un document."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß <b>Essayez √† pr√©sent de s√©lectionner et afficher les <i>tokens</i> \"tout le monde\".</b>\n",
    "\n",
    "<details>\n",
    "<summary>Indices</summary>\n",
    "\n",
    "Vous pouvez utiliser les *ranges* pour s√©lectionner plusieurs √©l√©ments d'un it√©rable. Voici un exemple de la syntaxe √† utiliser :\n",
    "```python\n",
    "ma_liste = [0, 1, 2, 3]\n",
    "print(ma_liste[1:3])\n",
    "# Affiche : [1, 2]\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "On applique cette syntaxe pour s√©lectionner les tokens du rang 1 (2e token, inclus) au rang 4 (non inclus) :\n",
    "\n",
    "```python\n",
    "span = doc[1:4]\n",
    "span\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut √©galement utiliser les \"ranges\" Python pour s√©lectionner plusieurs tokens\n",
    "span = doc[____]\n",
    "span"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä l'instar des objets Token, ils poss√®dent √©galement des [attributs](https://spacy.io/api/span#attributes) int√©ressants, comme `Span.text` qui permet d'en obtenir une repr√©sentation textuelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut √©galement acc√©der aux attributs d'un span\n",
    "span.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Reconna√Ætre des entit√©s nomm√©es avec un mod√®le existant et visualiser les r√©sultats ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons √† pr√©sent utiliser un mod√®le existant mis √† disposition par les cr√©ateurs de spaCy pour comprendre le fonctionnement d'un mod√®le de langue int√©grant un composant de reconnaissance d'entit√©s nomm√©es.\n",
    "\n",
    "Pour cela, nous allons commencer par utiliser une cha√Æne de traitement entra√Æn√©e pour le fran√ßais."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Choix, installation et chargement du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Cherchez [dans la documentation](https://spacy.io/models/fr) un mod√®le adapt√© pour d√©marrer\n",
    "Trouvez le nom du **plus petit mod√®le contenant un composant NER** qui nous permettra de faire des premi√®res exp√©riences rapides.\n",
    "\n",
    "La taille du mod√®le est indiqu√©e dans le champ *\"Size\"*.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "On trouve 4 mod√®les :\n",
    "1. `fr_core_news_sm` : un petit mod√®le adapt√© pour nos premi√®res exp√©riences, contenant tous les composants n√©cessaires üëà *utilisez celui-ci pour mettre au point votre approche !*\n",
    "2. `fr_core_news_md` : un mod√®le de taille moyenne, contenant √©galement tous les composants de base, adapt√© √† des cas simples pour lesquels l'efficacit√© prime\n",
    "3. `fr_core_news_lg` : un mod√®le large, adapt√© au travail sur CPU, contenant tous les composants de base et offrant de bonnes performances.\n",
    "4. `fr_dep_news_trf` : un nouveau mod√®le qui devrait offrir les meilleures performances, mais ne disposant pas de composant NER pr√©-entra√Æn√© et pour lequel il faut pr√©f√©rer une ex√©cution sur GPU.\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez √† pr√©sent la commande suivante pour t√©l√©charger les fichiers du mod√®le\n",
    "Indiquez le nom du mod√®le que vous avez s√©lectionn√©.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```\n",
    "!python -m spacy download fr_core_news_sm\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download __________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons √† pr√©sent charger ce nouveau mod√®le √† l'aide de la commande [`spacy.load(NOM_DU_MOD√àLE)`](https://spacy.io/api/top-level#spacy.load)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez la cellule suivante pour charger le mod√®le que vous venez de t√©l√©charger.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Ex√©cutez √† pr√©sent la cellule suivante pour v√©rifier que nous disposons bien de nouveau composants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Premiers pas avec un mod√®le sur √©tag√®re üì¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons √† pr√©sent utiliser notre mod√®le pour extraire des informations plus int√©ressantes d'un texte, comme de l'[√©tiquetage morpho-syntaxique](https://fr.wikipedia.org/wiki/%C3%89tiquetage_morpho-syntaxique), aussi appel√© √©tiquetage grammatical, ou *POS tagging* (*part-of-speech tagging*) en anglais, pour jouer un peu avant de nous recentrer sur la reconnaissance d'entit√©s nomm√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging example\n",
    "doc = nlp(\"La journ√©e de formation √† Lyon se d√©roule bien.\")\n",
    "print(f\"{'Token':>10s}\", f\"{'POS':>6s}\", f\"{'Synt. dep. rel.':>18s}\", f\"{'Synt. parent':>15s}\")\n",
    "print(\"-\"*50)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:>10s}\", f\"{token.pos_:>6s}\", f\"{token.dep_:>18s}\", f\"{token.head.text:>15s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ì Pourquoi certains [attributs des tokens](https://spacy.io/api/token#attributes) terminent-ils par un `_` ?  \n",
    "C'est parce que la valeur de base (sans le `_`) est un identifiant (un nombre entier) qui pointe vers une case d'un grand dictionnaire d'√©l√©ments connus. C'est une fa√ßon efficace, mais peu lisible, de stocker l'information. D'o√π la variante lisible !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est √©galement possible de demander √† spaCy des explications sur un terme utilis√© √† l'aide de la fonction `spacy.explain()`.\n",
    "\n",
    "Vous pouvez modifier la cellule ci-dessous pour obtenir plus d'information sur un terme si vous le souhaitez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"advmod\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Reconnaissance d'entit√©s nomm√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une nouvelle phrase qui contient deux entit√©s classiques : une **personne** (√† laquelle correspondra l'√©tiquette `PER`) et un **lieu** (qui sera rep√©r√© par l'√©tiquette `LOC`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Analysons-la avec notre nouveau mod√®le !\n",
    "Ex√©cutez la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Joseph est venu en train √† Lyon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien qu'on puisse lire la valeur de l'attribut `ent_type_` de chaque objet [`Token`](https://spacy.io/api/token#attributes), il est souvent plus pratique de ne lister que les entit√©s nomm√©es d√©tect√©es dans un document. De plus, certaines entit√©s peuvent contenir plusieurs *tokens*, ce qui rend leur extraction manuelle plus d√©licate !\n",
    "\n",
    "Heureusement, l'objet [`Doc`](https://spacy.io/api/doc) dispose d'une propri√©t√© [`Doc.ents`](https://spacy.io/api/doc#ents) qui renvoie une liste d'objets [`Span`](https://spacy.io/api/span) qui repr√©sentent les positions des entit√©s et les √©tiquettes (*labels*) qui leur sont associ√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez le code de la cellule ci-dessous pour afficher le texte et le *label* de chaque entit√©\n",
    "- Utilisez les attributs `start`, `end` de chaque `Span` pour s√©lectionner le fragment de document couvert √† l'aide d'un *range* Python\n",
    "- Utiliser leur attribut `label_` pour afficher le type d'entit√© d√©tect√© sous forme textuelle\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "for ent in doc.ents:\n",
    "    print(doc[ent.start:ent.end], ent.label_)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.____:\n",
    "    print(doc[____:____], ____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualisation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy dispose d'un moteur de visualisation tr√®s pratique, qui produit de tr√®s jolis r√©sultats.\n",
    "\n",
    "Il est utilisable via le module [`displacy`](https://spacy.io/universe/project/displacy) qui permet de visualiser les informations extraites d'un document, en particulier les [entit√©s nomm√©es](https://spacy.io/usage/visualizers#ent).\n",
    "\n",
    "Encore mieux, il peut √™tre [utilis√© dans un notebook](https://spacy.io/usage/visualizers#jupyter) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ì Vous pouvez m√™me modifier le style d'affichage en indiquant `\"dep\"` pour afficher le graphe de d√©pendances syntaxiques de notre document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "treacher"
    ]
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traiter les donn√©es de notre corpus d'exemple ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons √† pr√©sent utiliser notre mod√®le pour traiter les donn√©es de notre corpus et r√©aliser une premi√®re analyse qualitative superficielle des r√©sultats produits.\n",
    "\n",
    "Pour vous illustrer la proc√©dure √† suivre avec vos propres donn√©es, nous allons vous montrer comment acc√©der √† une collection de fichiers texte :\n",
    "1. si vous utilisez **Google Colab**, en utilisant le contenu d'un de vos dossiers Google Drive,\n",
    "2. si vous utilisez **votre propre machine**, en indiquant simplement le chemin vers lequel les fichiers sont stock√©s.\n",
    "\n",
    "Ces deux cas sont assez semblables, la seule diff√©rence est qu'avec Google Colab, vous utiliser une machine virtuelle distance, et que vous ne pouvez contr√¥ler cette derni√®re que par l'interm√©diaire de l'interface de Colab (un notebook am√©lior√©)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è R√©cup√©rer des fichiers int√©ressants sur votre machine\n",
    "Vous allez t√©l√©charger le jeu de donn√©es original ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù par Carmen Brando, Francesca Frontini, et Ioana Galleron.\n",
    "\n",
    "[![üì¶ Cliquez ici pour t√©l√©charger le jeu de donn√©es](https://img.shields.io/badge/%F0%9F%93%A6-Cliquez_ici_pour_t%C3%A9l%C3%A9charger_le_jeu_de_donn%C3%A9es-blue)](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/bitstream/handle/20.500.11752/OPEN-986/French_ELTEC_NER_Open_Dataset.zip) et enregistrez-le quelque-part sur votre ordinateur personnel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Utiliser Drive pour envoyer des fichiers sur Colab\n",
    "**Si vous ex√©cutez votre *notebook* sur votre propre machine, vous pouvez passer cette partie.**\n",
    "\n",
    "√Ä pr√©sent, copiez le fichier Zip t√©l√©charg√© dans un dossier de votre choix (par exemple \"Formation Ariane\") de votre Drive.\n",
    "\n",
    "Nous sommes maintenant pr√™ts √† \"monter\" votre Drive sur la machine virtuelle que vous utilisez sur Google Colab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©tez et ex√©cutez la cellule ci-dessous et autorisez Colab √† acc√©der √† votre Drive\n",
    "Une fois cette op√©ration r√©alis√©e, votre machine virtuelle Google Colab pourra acc√©der au fichier que vous venez de d√©poser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "# COMPL√âTEZ CETTE LIGNE AVEC LE NOM DU DOSSIER DANS LEQUEL VOUS AVEZ D√âPOS√â VOTRE FICHIER\n",
    "# > just access \"/gdrive/My Drive/...\"\n",
    "FOLDER_NAME = \"Formation Ariane\"  # üëàüëàüëà\n",
    "\n",
    "# Si vous avez chang√© le nom du fichier, vous pouvez l'indiquer ici\n",
    "ZIP_FILENAME = \"French_ELTEC_NER_Open_Dataset.zip\"\n",
    "\n",
    "# On v√©rifie qu'on arrive bien √† acc√©der au fichier\n",
    "import os.path\n",
    "dataset_zip_path = f\"/gdrive/My Drive/{FOLDER_NAME}/{ZIP_FILENAME}\"\n",
    "if os.path.exists(dataset_zip_path):\n",
    "    print(\"Fichier bien trouv√© !\")\n",
    "else:\n",
    "    err_msg = f\"Erreur, le fichier n'a pas √©t√© trouv√© au chemin '{dataset_zip_path}'.\"\n",
    "    print(err_msg)\n",
    "    raise ValueError(err_msg)\n",
    "dataset_destination_dir = \"./dataset/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Si vous travaillez sur votre machine personnelle, d√©-commentez, modifiez et ex√©cutez la cellule suivante\n",
    "Ceci nous servira √† indiquer :\n",
    "1. o√π est rang√© le fichier ZIP contenant le jeu de donn√©es\n",
    "2. o√π il faudra d√©compresser les fichiers qu'il contient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_zip_path = \"/home/jchazalo/Downloads/French_ELTEC_NER_Open_Dataset.zip\"\n",
    "# dataset_destination_dir = \"/home/jchazalo/tmp/datasets\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 D√©compresser les fichiers\n",
    "Afin de faciliter l'acc√®s aux diff√©rents fichiers, nous allons √† pr√©sent d√©compresser les fichiers du jeu de donn√©es.\n",
    "\n",
    "Nous allons utiliser les 100 fichiers texte extraits de romans du 19e si√®cle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Ex√©cutez la cellule suivante et v√©rifiez qu'aucune erreur n'est rencontr√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence par v√©rifier qu'on trouve bien le fichier et que son contenu n'a pas √©t√© alt√©r√©\n",
    "!echo \"7dc395be9d84ac481ff6cf0a726862b66967898986f387dd5659d554394101d6  {dataset_zip_path}\" | sha256sum -c -\n",
    "# On v√©rifie que le r√©pertoire de destination existe et on le cr√©e sinon\n",
    "!mkdir -p \"{dataset_destination_dir}\"\n",
    "# On d√©compresse le fichier dans le r√©pertoire de destination\n",
    "!unzip \"{dataset_zip_path}\" -d \"{dataset_destination_dir}\"\n",
    "# On liste le contenu du r√©pertoire de destination : on s'attend √† trouver le r√©pertoire \"French_ELTEC_NER_Open_Dataset/texts\" et √† ce qu'il contienne des fichiers texte\n",
    "!ls -lA \"{dataset_destination_dir}/French_ELTEC_NER_Open_Dataset/texts\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfait ! Nous avons des fichiers pr√™ts √† √™tre trait√©s ü¶æ !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Construire une liste de fichiers √† traiter\n",
    "\n",
    "Nous allons devoir charger chacun des fichiers du corpus et les passer √† notre mod√®le de langue `nlp`.\n",
    "\n",
    "Nous allons proc√©der de la fa√ßon suivante :\n",
    "\n",
    "1. nous allons construire la liste des chemins vers chacun de ces fichiers √† traiter\n",
    "2. nous allons d√©finir une fonction qui permet de charger le contenu de ces fichiers\n",
    "3. nous allons regarder les r√©sultats pour quelques fichiers\n",
    "4. finalement nous allons appeler notre mod√®le de langue avec le contenu de chacun de ces fichiers, pour stocker les entit√©s d√©tect√©es dans une grande liste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour lister les fichiers, nous allons utiliser le module Python [`glob`](https://docs.python.org/3/library/glob.html) qui permet d'obtenir une liste de fichier √† partir d'un motif.\n",
    "\n",
    "Nous allons utiliser un motif simple en indiquant un caract√®re joker `*` pour indiquer que n'importe quel caract√®re peut √™tre trouv√© √† cette position."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Corrigez l'extension des fichiers √† trouver dans la cellule suivante pour collecter la liste des fichiers texte √† traiter\n",
    "Nous allons afficher le contenu de cette liste pour v√©rifier que nous avons bien trouv√© les fichiers √† traiter.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "Remplacez le `*.json` par `*.txt`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "text_file_paths = glob(f\"{dataset_destination_dir}/French_ELTEC_NER_Open_Dataset/texts/*.json\")\n",
    "text_file_paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©tez la cellule suivante pour v√©rifier que nous avons bien trouv√© 100 fichiers\n",
    "<details>\n",
    "<summary>Indice</summary>\n",
    "V√©rifiez que la liste des noms de fichiers contient bien 100 √©l√©ments.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "len(text_file_paths)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(text_file_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Observation des r√©sultats pour quelques textes\n",
    "Avant de traiter les donn√©es, nous allons v√©rifier que le mod√®le de langue produit des r√©sultats raisonnables sur quelques exemples.\n",
    "\n",
    "Si ces r√©sultats sont satisfaisants, alors nous pourrons lancer un traitement plus large, et, plus tard, mesurer la performance de fa√ßon objective sur un √©chantillon repr√©sentatif, de taille suffisante, annot√© de fa√ßon fiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vous aider, voici une fonction `load_text(filename)` qui prend en param√®tre un chemin vers un fichier texte et renvoie la (longue) cha√Æne de caract√®res de son contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filename: str) -> str:\n",
    "    \"\"\"Loads and returns the content of a text file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the text file\n",
    "\n",
    "    Returns:\n",
    "        str: String representation of the content of the file. Newlines are preserved.\n",
    "    \"\"\"\n",
    "    with open(filename, encoding=\"utf8\") as in_file:\n",
    "        return \"\".join(in_file.readlines())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©ter la cellule suivante pour traiter et visualiser les entit√©s extraites d'un texte de votre choix\n",
    "Si n√©cessaire, consultez les √©tapes pr√©c√©dentes pour retrouver les op√©rations r√©alis√©es.\n",
    "\n",
    "Rappel : la variable qui pointe vers notre mod√®le de langue s'appelle `nlp`.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "some_filename = text_file_paths[10]\n",
    "some_text = load_text(some_filename)\n",
    "some_doc = nlp(some_text)\n",
    "displacy.render(some_doc, style=\"ent\", jupyter=True)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On choisit un fichier parmi la liste des fichiers disponibles\n",
    "some_filename = text_file_paths[10]\n",
    "# On charge son contenu\n",
    "some_text = load_text(____)\n",
    "# On applique notre mod√®le de langue pour extraire des entit√©s nomm√©es (entre autres)\n",
    "some_doc = ___(____)\n",
    "# On utilise displaCy pour visualiser les entit√©s nomm√©es d√©tect√©es dans ce texte\n",
    "____.render(____, style=____, jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu'en pensez-vous ?**  \n",
    "‚Äî Pas si mal, √† premi√®re vue, pour un mod√®le de langue minimaliste !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Traiter les donn√©es de fa√ßon massive\n",
    "\n",
    "Nous allons traiter chacun des textes et r√©cup√©rer le texte des entit√©s nomm√©es de type \"`LOC`\" pour les ajouter √† une liste.\n",
    "\n",
    "Cette liste contiendra des √©l√©ments qui nous int√©ressent (comment \"Paris\", \"Bretagne\"), ne contiendra pas quelques √©l√©ments manqu√©s, et contiendra en plus quelques √©l√©ments de bruit faussement d√©tect√©s comme des entit√©s de type `LOC`.\n",
    "\n",
    "Afin de diminuer le plus possible le temps de calcul, nous allons r√©aliser un certain nombre d'optimisations :\n",
    "\n",
    "- nous allons charger les fichiers texte √† la demande pour limiter l'utilisation de la m√©moire de la machine et commencer √† les analyser d√®s qu'ils sont charg√©s (au lieu d'attendre de tous les charger) ‚Üí utilisation d'un g√©n√©rateur Python\n",
    "- nous allons temporairement [limiter les composants actifs de notre mod√®le de langue](https://spacy.io/usage/processing-pipelines#disabling) afin de ne calculer que les √©l√©ments n√©cessaires √† la reconnaissance d'entit√©s nomm√©es ‚Üí utilisation du *context manager* [`Language.select_pipes()`](https://spacy.io/api/language#select_pipes),\n",
    "- nous allons utiliser la fonctionnalit√© de traitement √† la vol√©e de spaCy pour acc√©l√©rer les calculs et limiter l'utilisation de la m√©moire ‚Üí m√©thode [`Language.pipe()`](https://spacy.io/api/language#pipe),\n",
    "- nous allons analyser les documents au fur et √† mesure de leur analyse pour en extraire les entit√©s qui nous int√©ressent ‚Üí parcours des √©l√©ments [`Doc.ents`](https://spacy.io/api/doc#ents) et s√©lection des √©l√©ments dont l'attribut [`Span.label_`](https://spacy.io/api/span#attributes) nous convient,\n",
    "- et finalement nous ne stockerons que le texte des entit√©s nomm√©es, et non l'objet [`Span`](https://spacy.io/api/span) complet qui contient une r√©f√©rence vers tout le texte du document, afin de limiter l'utilisation m√©moire.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©ter la cellule suivante pour traiter tous les fichiers texte du corpus\n",
    "Rappel : la variable qui pointe vers notre mod√®le de langue s'appelle `nlp`.\n",
    "\n",
    "Convention : nous d√©finissons une variable `all_loc_entities: list[str]` qui contiendra le texte de toutes nos entit√©s.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "texts = (load_text(filename) for filename in text_file_paths)\n",
    "all_loc_entities: list[str] = []\n",
    "with nlp.select_pipes(enable=\"ner\"):\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"LOC\":\n",
    "                all_loc_entities.append(ent.text)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ‚Üë l'instruction ci-dessus sert √† mesurer le temps d'ex√©cution de la cellule courante\n",
    "texts = (load_text(filename) for filename in text_file_paths)  # on charge les fichiers √† la demande avec un g√©n√©rateur\n",
    "all_loc_entities: list[str] = []  # la liste qui va stocker nos r√©sultats : une simple liste d'entit√©s nomm√©es\n",
    "with nlp.____(enable=____):  # on restreint les calculs au composant \"ner\" exclusivement pour aller plus vite\n",
    "    for doc in nlp.____(texts):  # on utilise le traitement √† la vol√©e\n",
    "        for ent in doc.____:  # on parcourt les entit√©s du document\n",
    "            if ent.label_ == ____:  # on ne conserve que les entit√©s du type qui nous int√©resse\n",
    "                all_loc_entities.append(ent.____)  # on ne conserve que le texte et pas toute l'entit√© pour √©viter de garder le document en m√©moire\n",
    "# On affiche le nombre d'entit√©s nomm√©es trouv√©es\n",
    "len(all_loc_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voici les premiers √©l√©ments de cette grande liste\n",
    "all_loc_entities[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è∞ O√π en √™tes-vous ?\n",
    "\n",
    "**Si vous n'avez pas le temps d'aller plus loin, ce n'est pas grave** : vous pourrez finir cette activit√© chez vous.\n",
    "üéâ Vous avez d√©j√† r√©ussi √† produire des donn√©es dans un format qui peut √™tre utile pour une analyse ult√©rieure.\n",
    "**Vous pouvez passer directement √† l'√©tape 8 d'export des donn√©es** pour avoir une vision compl√®te de la phase d'extraction de donn√©es.\n",
    "\n",
    "ü§ì Dans ce qui suit, nous allons essayer d'aller plus loin pour :\n",
    "- mettre en place un protocole d'√©valuation rigoureux nous permettant de comparer la performance de diff√©rents mod√®les (et ne pas nous contenter du mod√®le le plus l√©ger de spaCy)\n",
    "- entra√Æner un mod√®le sp√©cialis√© pour l'analyse de nos donn√©es, en v√©rifiant bien qu'il nous apporte un gain par rapport aux mod√®les existants !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluer objectivement la performance d'un mod√®le de langage ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Un probl√®me de d√©tection\n",
    "\n",
    "Dans le cas de la reconnaissance d'entit√©s nomm√©es, le probl√®me est g√©n√©ralement consid√©r√© comme un probl√®me de **d√©tection**, c'est-√†-dire qu'il s'agit de rep√©rer la position et le type de donn√©es d'int√©r√™t dans un ensemble de donn√©es : texte, image, son‚Ä¶\n",
    "\n",
    "D√©tecter un √©l√©ment dans du texte revient √† identifier :\n",
    "- sa position initiale,\n",
    "- sa position finale,\n",
    "- son type.\n",
    "\n",
    "C'est exactement pour d√©crire ce type d'objet que les [`Span`](https://spacy.io/api/span) existent : leurs attributs `start`, `end` et `label_` contiennent ces informations.\n",
    "\n",
    "L'exemple ci-dessous montre comment :\n",
    "1. cr√©er un document sans en extraire aucune autre information que les *tokens* gr√¢ce √† la m√©thode [`Language.make_doc(text)`](https://spacy.io/api/Language#attributes)\n",
    "2. cr√©er un objet [`Span`](https://spacy.io/api/Span#init) avec les param√®tres utiles :\n",
    "   - les positions correspondent au caract√®re (ou token) de d√©but, et au caract√®re (ou token) apr√®s la fin, index√©es √† partir de 0\n",
    "   - la valeur de son √©tiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1 avec `Doc.char_span` \n",
    "# ‚Üí les positions sont correspondent √† des caract√®res !\n",
    "doc = nlp.make_doc(\"Il est parti de Paris t√¥t ce matin.\")\n",
    "span = doc.char_span(16, 21, label=\"LOC\")  \n",
    "span  # on affiche l'objet cr√©√© pour v√©rifier qu'on a saisi les bonnes valeurs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1 avec la construction directe d'un `Span`\n",
    "# ‚Üí c'est pratique car les positions correspondent aux tokens : plus facile √† saisir\n",
    "# ‚Üí mais il faut indiquer le document auquel on fait r√©f√©rence\n",
    "from spacy.tokens import Span\n",
    "doc = nlp.make_doc(\"Il est parti de Paris t√¥t ce matin.\")\n",
    "span = Span(doc, 4, 5, label=\"LOC\")\n",
    "span  # on affiche l'objet cr√©√© pour v√©rifier qu'on a saisi les bonnes valeurs !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Bases th√©oriques\n",
    "\n",
    "Pour √©valuer objectivement la performance d'un syst√®me de traitement de donn√©es, il nous faut 3 choses :\n",
    "1. un **ensemble de couples (donn√©es d'entr√©e, donn√©e id√©ale de sortie)** ‚Äî exemple : un texte et la liste des positions et types des entit√©s nomm√©es √† d√©tecter\n",
    "2. les **donn√©es produites par le syst√®me** √† √©valuer pour chacune des donn√©es d'entr√©e de l'ensemble pr√©c√©dent\n",
    "3. une **mesure permettant de comparer** les donn√©es produites et les donn√©es attendues\n",
    "\n",
    "Nous venons de voir qu'il est possible de repr√©senter les donn√©es produites (on dit plus souvent *\"pr√©dites\"*) et les donn√©es attendues √† l'aide de d'objets [`Span`](https://spacy.io/api/Span#init).\n",
    "\n",
    "Mais **comment les comparer**, et surtout **calculer une valeur qui r√©sume la ressemblance entre deux ensembles** de positions et types pr√©dits ou attendus ?\n",
    "\n",
    "C'est tr√®s simple en r√©alit√©, car le probl√®me de d√©tection dispose de mesures standard et fiables :\n",
    "- la [**pr√©cision**](https://en.wikipedia.org/wiki/Precision_and_recall), not√©e $P$, qui mesure la quantit√© de bruit dans les r√©sultats.\n",
    "  Elle est d√©finie comme  \n",
    "  $$P = \\frac{\\text{nombre d'√©l√©ments corrects}}{\\text{nombre d'√©l√©ments d√©tect√©s}}$$\n",
    "- le [**rappel**](https://en.wikipedia.org/wiki/Precision_and_recall), not√© $R$, qui mesure la proportion d'√©l√©ments manqu√©s dans les r√©sultats.\n",
    "  Il est d√©fini comme  \n",
    "  $$R = \\frac{\\text{nombre d'√©l√©ments corrects}}{\\text{nombre d'√©l√©ments attendus}}$$\n",
    "- le [**F-score**](https://en.wikipedia.org/wiki/F-score), not√© $F$, qui synth√©tise ces deux indicateurs en calculant leur moyenne harmonique.\n",
    "  Il est d√©fini par \n",
    "  $$F = 2 \\times \\frac{P \\times R}{P + R}$$\n",
    "\n",
    "Pour chacune de ces mesures, la **valeur minimale (pire cas) est $0$**, et la **valeur maximale (d√©tection parfaite) est $1$**.\n",
    "Il est courant d'indiquer des pourcentages lorsqu'on parle de ces valeurs (il suffit de les multiplier par 100).\n",
    "\n",
    "#### üßê Bon, tout √ßa c'est bien joli, mais comment fait-on pour **savoir qu'un √©l√©ment pr√©dit correspond √† un √©l√©ment attendu** ?\n",
    "Dans notre cas, c'est tr√®s simple ! Il suffit de consid√©rer que les √©l√©ments doivent avoir **exactement la m√™me position et la m√™me √©tiquette.** Si un √©l√©ment attendu n'a aucune correspondance, alors on dit qu'il a √©t√© manqu√©, et au contraire si un √©l√©ment pr√©dit ne correspond √† aucun √©l√©ment attendu, alors on dit qu'il s'agit d'une fausse d√©tection (on dit aussi \"du bruit\").\n",
    "\n",
    "#### Mesures par classe\n",
    "En g√©n√©ral, on s'int√©resse √† un type de donn√©es particulier, aussi les outils de mesure rapportent g√©n√©ralement les mesures de pr√©cision, rappel et F-score pour chaque classe (par exemple \"LOC\"). Il s'agit du m√™me calcul que pr√©c√©demment, mais en restreignant les √©l√©ments consid√©r√©s √† un type d'√©tiquette pr√©cis.\n",
    "\n",
    "#### ü§ì Bon √† savoir : on donne de multiples noms aux donn√©es attendues :\n",
    "- donn√©es cibles (*targets*)\n",
    "- v√©rit√© terrain (*ground truth*)\n",
    "- valeurs de r√©f√©rence (*gold standard*)\n",
    "- ‚Ä¶"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Place √† la pratique !\n",
    "Nous allons g√©n√©rer des donn√©es pr√©dites et des donn√©es de r√©f√©rence factices pour quelques fragments de texte simplistes, et nous allons calculer les diff√©rents scores pour chacun d'entre eux, de mani√®re √† comprendre le comportement de la pr√©cision, du rappel et du F-score (celui qui nous int√©resse le plus).\n",
    "\n",
    "Avant de r√©aliser des mesures, nous avons besoin de comprendre le r√¥le de deux types d'objets spaCy suppl√©mentaires :\n",
    "- [`Scorer`](https://spacy.io/api/scorer) : il est responsable de la **comparaison entre les documents de r√©f√©rence et les documents pr√©dits**. Il renvoie les mesures pour toutes les donn√©es disponibles (donc pas seulement le NER si on ne pr√©cise rien). Dans notre cas, nous utiliserons la m√©thode [`Scorer.score_spans(examples, \"ents\")`](https://spacy.io/api/scorer#score_spans) qui nous permettra de restreindre l'√©valuation aux entit√©s nomm√©es. L'utilisation typique sera la suivante :  \n",
    "    ```python\n",
    "    scorer = Scorer()\n",
    "    scores = Scorer.score_spans(examples, \"ents\")\n",
    "    ```\n",
    "- [`Example`](https://spacy.io/api/example) : on l'a vu dans l'exemple pr√©c√©dent : il faut des exemples pour appeler le `Scorer`. Ces exemples correspondent √† des **paires de documents**, qui sont bas√©s sur le **m√™me texte** : un document contenant les **valeurs pr√©dites**, et un document contenant les **valeurs de r√©f√©rence**. Pour construire un exemple, on a donc besoin de cr√©er deux documents :\n",
    "    ```python\n",
    "    text = \"Bonjour de Lyon\"\n",
    "    doc_pred = nlp(text)\n",
    "    doc_ref = nlp.make_doc(text)\n",
    "    doc_ref.ents = [Span(doc_ref, 2, 3, \"LOC\")]\n",
    "    exemple = Example(doc_pred, doc_ref)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Compl√©tez les d√©finitions des Spans ci-dessous pour constituer une v√©rit√© terrain parfaite\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 4, 5, label=\"LOC\"),\n",
    "    ]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1 : La r√©f√©rence et la pr√©diction coincident\n",
    "text1 = \"Alice est all√©e √† Amsterdam l'an dernier et elle a trouv√© les canaux magnifiques.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(_____, __, __, label=____),\n",
    "    Span(_____, __, __, label=____),\n",
    "    ]\n",
    "doc1_ref.ents  # On verifie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Appelez √† pr√©sent notre mod√®le de langue sur le m√™me texte pour d√©finir la pr√©diction\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "doc1_pred = nlp(text1)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1_pred = ___(_____)  # Par chance, le mod√®le de base indique les bons r√©sultats !\n",
    "doc1_pred.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Cr√©ez √† pr√©sent un `Example` qui contient les deux documents, et passez une __liste__ d'exemples au `Scorer`\n",
    "\n",
    "Faites attention √† l'ordre des param√®tres pour construire un [`Example`](https://spacy.io/api/example#init) : le premier est la pr√©diction, le second la r√©f√©rence.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "example = Example(doc1_pred, doc1_ref)\n",
    "scorer = Scorer()\n",
    "score = scorer.score_spans([example], attr=\"ents\")\n",
    "score\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = Example(_____, _____)\n",
    "scorer = Scorer()\n",
    "score = scorer.score_spans(_____, attr=\"ents\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit v√©rifier que tous les indicateurs sont √† 1 (la valeur maximale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä pr√©sent, nous pouvons adapter l'exemple pr√©c√©dent pour tester les cas suivants et observer l'impact sur les diff√©rents scores :\n",
    "- une entit√© attendue est manqu√©e\n",
    "- une entit√© est pr√©dite par erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Adaptez le code suivant pour tester les cas que nous venons de mentionner\n",
    "\n",
    "Nous allons simuler des d√©tections erron√©es plut√¥t que d'essayer de pi√©ger le mod√®le de langue.\n",
    "\n",
    "Observez l'impact des oublis et des fausses d√©tection sur la pr√©cision, le rappel et le F-score.\n",
    "\n",
    "<details>\n",
    "<summary>Solution cas 1</summary>\n",
    "\n",
    "```python\n",
    "text1 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc1_ref.ents  # On verifie\n",
    "doc1_pred = nlp.make_doc(text1)\n",
    "doc1_pred.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),  # Il manque Alex\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "example1 = Example(doc1_pred, doc1_ref)\n",
    "scorer.score_spans([example1], attr=\"ents\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary>Solution cas 2</summary>\n",
    "\n",
    "```python\n",
    "text2 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc2_ref = nlp.make_doc(text2)\n",
    "doc2_ref.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc2_ref.ents  # On verifie\n",
    "doc2_pred = nlp.make_doc(text2)\n",
    "doc2_pred.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    Span(doc2_ref, 10, 11, label=\"LOC\"),  # \"dernier\" d√©tect√© par erreur\n",
    "    ]\n",
    "example2 = Example(doc2_pred, doc2_ref)\n",
    "scorer.score_spans([example2], attr=\"ents\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAS 1 : UNE ENTIT√â ATTENDUE EST MANQU√âE\n",
    "text1 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "# doc1_ref.ents  # On verifie\n",
    "doc1_pred = nlp.make_doc(text1)\n",
    "doc1_pred.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "example1 = Example(doc1_pred, doc1_ref)\n",
    "scorer.score_spans([example1], attr=\"ents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAS 2 : UNE ENTIT√â EST PR√âDITE PAR ERREUR\n",
    "text2 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc2_ref = nlp.make_doc(text2)\n",
    "doc2_ref.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "# doc2_ref.ents  # On verifie\n",
    "doc2_pred = nlp.make_doc(text2)\n",
    "doc2_pred.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "example2 = Example(doc2_pred, doc2_ref)\n",
    "scorer.score_spans([example2], attr=\"ents\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Annoter un jeu de donn√©es complet : aper√ßu du probl√®me ‚Äî *‚è±Ô∏è 5 mn*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En g√©n√©ral, on a besoin de constituer et d'annoter un nouveau de donn√©es pour (au moins) une des deux raisons suivantes :\n",
    "1. Pour **√©valuer** rigoureusement la performance d'un ou plusieurs syst√®mes de traitement de donn√©es. Dans ce cas, on parle g√©n√©ralement de **jeu de test**, de **d√©veloppement** ou de **validation** (notions voisines sans √™tre exactement √©quivalentes). Il faut des donn√©es d'une quantit√© et d'une vari√©t√© suffisantes pour que les r√©sultats soient significatifs. Ce jeu de donn√©es ne peut pas contenir de donn√©es vues pendant l'entra√Ænement.\n",
    "2. Pour **entra√Æner** ou **sp√©cialiser** un mod√®le de langue bas√© sur une approche statistique. Dans ce cas, on parle de **jeu d'entra√Ænement** (*\"train set\"*). On a g√©n√©ralement besoin d'une quantit√© de donn√©es plus importante pour permettre la stabilisation des param√®tres statistiques du mod√®le. Ici aussi, ces donn√©es doivent √™tre suffisamment vari√©es pour permettre de capturer les subtilit√©s des donn√©es √† traiter, et assez repr√©sentatives pour capturer en priorit√© les g√©n√©ralit√©s.\n",
    "\n",
    "\n",
    "Dans les 2 cas, comme nous n'avons vu dans la section pr√©c√©dente, il faut pr√©parer :\n",
    "- des exemples de donn√©es d'entr√©e pour le syst√®me (√©chantillons de textes)\n",
    "- les sorties parfaites attendues pour ces donn√©es (dans le cas du NER, liste des entit√©s ‚Äî avec position et √©tiquette ‚Äî √† extraire).\n",
    "\n",
    "\n",
    "La fa√ßon la plus √©l√©mentaire de r√©aliser ce travail peut se d√©composer en :\n",
    "1. **identifier** un groupe de textes √† √©tiqueter,\n",
    "2. **importer** les textes dans un outil d'annotation et les **annoter**,\n",
    "3. **exporter** les donn√©es et les **convertir** dans un format adapt√©."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Quelques outils d'annotation\n",
    "- [ner-annotator](https://tecoholic.github.io/ner-annotator) : un petit outil libre et gratuit, tr√®s simple, qui a le m√©rite d'√™tre rapide √† utiliser pour illustrer la d√©marche.\n",
    "- [Brat](http://brat.nlplab.org/) : un outil libre et gratuit, plus complet, mais qui n√©cessite une installation.\n",
    "- [LabelStudio](https://labelstud.io/) : un outil autre libre et gratuit, assez complet, qui n√©cessite une installation mais peut aussi √™tre utilis√© en ligne.\n",
    "- [UniversalDataTool](https://universaldatatool.com) : un outil autre libre et gratuit, assez complet, qui n√©cessite une installation mais peut aussi √™tre utilis√© en ligne, et qui offre des fonctionnalit√©s de collaboration.\n",
    "- [TagTog](https://www.tagtog.com/) : un outil en ligne payant, offrant de nombreuses fonctionnalit√©s, mais qui ne semble plus trop maintenu.\n",
    "- [Prodigy](https://prodi.gy/) : un outil en ligne, payant, d√©velopp√© par les cr√©ateurs de spaCy, qui offre de nombreuses fonctionnalit√©s."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Place √† la pratique !\n",
    "\n",
    "Pour appr√©hender rapidement les joies et peines de l'annotation, nous vous proposons d'annoter (au moins partiellement) un texte choisi au hasard parmi ceux du corpus.\n",
    "\n",
    "Vous pouvez soit s√©lectionner un des textes du corpus sur votre ordinateur, soit en t√©l√©charger un au hasard depuis la machine virtuelle Colab en ex√©cutant la cellule ci-dessous.\n",
    "\n",
    "Ensuite, consultez la page <https://tecoholic.github.io/ner-annotator/> pour r√©aliser une annotation rapide :\n",
    "1. d√©posez votre fichier texte,\n",
    "2. configurer les tags √† utiliser,\n",
    "3. annotez le texte,\n",
    "4. t√©l√©chargez vos annotations au format JSON, qui pourront facilement √™tre [converties au format spaCy](https://spacy.io/api/data-formats#json-input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a file from the VM\n",
    "from google.colab import files\n",
    "files.download(text_file_paths[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon √† savoir : il existe plusieurs techniques pour pr√©m√¢cher le travail :\n",
    "- utiliser un premier mod√®le de langue qui donne des r√©sultats moyens, mais qui permet toutefois de gagner du temps (ce n'est pas toujours le cas)\n",
    "- chercher des motifs particuliers en utilisant un [`Matcher`](https://spacy.io/api/matcher) ; c'est rapide mais il faut avoir une bonne connaissance de notre corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ì Pour aller plus loin\n",
    "Voici quelques questions qu'on se pose g√©n√©ralement lorsqu'on d√©marre une campagne d'annotation.\n",
    "- Quelles √©tiquettes/labels utiliser ?\n",
    "- Quelles r√®gles suivre, comment g√©rer les ambigu√Øt√©s ?\n",
    "- Comment distribuer le travail entre plusieurs annotateurs ? Comment assurer la coh√©rence entre le travail des diff√©rents annotateurs ?\n",
    "- Comment diffuser notre travail, le partager, quelle licence utiliser ?\n",
    "\n",
    "Toutes ces questions m√©riteraient un atelier d√©di√©‚Ä¶\n",
    "\n",
    "*Sachez juste qu'il faut essayer de d√©marrer peu de donn√©es et valider l'int√©gralit√© du processus avant d'investir massivement dans un effort d'annotation.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entra√Æner un mod√®le sp√©cialis√© et comparer sa performance ‚Äî *‚è±Ô∏è 10 mn*\n",
    "\n",
    "Enfin, nous allons nous int√©resser √† l'entra√Ænement d'un mod√®le sp√©cialis√© pour nos donn√©es.\n",
    "En effet, il est parfois possible de d√©passer la performance des mod√®les \"sur √©tag√®re\" sur des cas particuliers mal g√©r√©s par des mod√®les g√©n√©ralistes.\n",
    "\n",
    "Nous allons utiliser des donn√©es d'entra√Ænement et de test que nous avons pr√©par√©es pour vous √† partir du jeu de donn√©es ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù.\n",
    "Si vous le souhaitez, vous pourrez regarder plus tard comment nous avons proc√©d√© dans les [notebooks](https://github.com/jchazalon/hn-ariane-ner-tuto-2023/blob/main/preparation/2-preparation-nettoyage-donnees-export-json.ipynb) [d√©di√©s](https://github.com/jchazalon/hn-ariane-ner-tuto-2023/blob/main/preparation/4-bench-mdls-convert-data-train-model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous utilisez Google Colab, vous devrez t√©l√©charger ces fichiers en ex√©cutant la cellule suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour t√©l√©charger les jeux d'entra√Ænement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du r√©pertoire si n√©cessaire\n",
    "!mkdir -p ./dataset\n",
    "# T√©l√©chargement du dataset\n",
    "!wget -O ./dataset/train.spacy https://github.com/jchazalon/hn-ariane-ner-tuto-2023/raw/main/dataset/train.spacy\n",
    "!wget -O ./dataset/test.spacy https://github.com/jchazalon/hn-ariane-ner-tuto-2023/raw/main/dataset/test.spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 √âvaluation des mod√®les disponibles\n",
    "\n",
    "Nous allons commencer par mesurer la performance des mod√®les d√©j√† disponibles avant d'en entra√Æner un nouveau.\n",
    "\n",
    "Nous allons vous fournir deux √©l√©ments utiles :\n",
    "- un **jeu de test** `test_set` que nous utiliserons pour comparer les mod√®les (et qui ne sera pas utilis√© pour entra√Æner notre mod√®le par la suite),\n",
    "- une **fonction d'√©valuation** `evaluate(model, dataset)` qui permet d'√©valuer un mod√®le sur un jeu de test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß √Ä vous de jouer\n",
    "Comme indiqu√© dans [la documentation](https://spacy.io/models/fr), trois mod√®les en fran√ßais sont disponibles pour reconna√Ætre des entit√©s nomm√©es :\n",
    "- `fr_core_news_sm` : version *small*\n",
    "- `fr_core_news_md` : version *medium*\n",
    "- `fr_core_news_lg` : version *large*\n",
    "\n",
    "Utilisez la fonction `evaluate(model, dataset)` et le jeu de teste `train_set` fournis ci-apr√®s pour √©valuer la performance de ces trois mod√®les.\n",
    "\n",
    "N'oubliez pas de :\n",
    "- t√©l√©charger ces mod√®les si c'est n√©cessaire avec la commande `!python -m spacy download NOM_DU_MODELE`\n",
    "- de charger ces mod√®les avec l'instruction `model = spacy.load(NUM_DU_MODELE)`\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "models_to_test = (\"fr_core_news_sm\", \"fr_core_news_md\", \"fr_core_news_lg\")\n",
    "for model_name in models_to_test:\n",
    "    print(f\"Installing model '{model_name}'‚Ä¶\")\n",
    "    !python -m spacy download {model_name}\n",
    "for model_name in models_to_test:\n",
    "    print(f\"Try to load the model '{model_name}'‚Ä¶\")\n",
    "    model = spacy.load(model_name)\n",
    "    print(f\"Benchmarking the model '{model_name}' on our dataset‚Ä¶\")\n",
    "    scores = evaluate(model, test_set)\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"-\"*20)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "test_set = DocBin().from_disk(\"./dataset/test.spacy\")\n",
    "print(f\"Loaded a dataset with {len(test_set)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from spacy import Language\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "def evaluate(ner_model: Language, dataset: Iterable[Doc], debug: bool=False) -> dict:\n",
    "    examples = []\n",
    "    for doc_ref in dataset.get_docs(ner_model.vocab):\n",
    "        text = doc_ref.text\n",
    "        # doc_pred = None\n",
    "        # with ner_model.select_pipes(enable=\"ner\"):  # does not work with trained model\n",
    "        #     doc_pred = ner_model(text)\n",
    "        doc_pred = ner_model(text)\n",
    "        if debug:\n",
    "            print(\"Pred.:\", [(ent.text, ent.label_) for ent in doc_pred.ents], \" ‚Üî Targ.:\", [(ent.text, ent.label_) for ent in doc_ref.ents])\n",
    "        example = Example(doc_pred, doc_ref)\n",
    "        examples.append(example)\n",
    "    \n",
    "    scorer = Scorer()\n",
    "    scores = scorer.score_spans(examples, \"ents\")\n",
    "    # print(scores[\"ents_f\"])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez votre code ici pour √©valuer les diff√©rents mod√®les\n",
    "# N'h√©sitez pas √† utiliser plusieurs cellules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans nos tests, nous avons obtenus les F-scores suivants pour les entit√©s de types `LOC`, pouvez-vous retrouver des valeurs similaires dans vos r√©sultats ?\n",
    "\n",
    "| Mod√®le | F-Score pour entit√©s `LOC` |\n",
    "|--------|---------------------------:|\n",
    "| `fr_core_news_sm` | 58% |\n",
    "| `fr_core_news_md` | 65% |\n",
    "| `fr_core_news_lg` | 68% |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Entra√Ænement d'un mod√®le l√©ger *from scratch*\n",
    "\n",
    "Un entra√Ænement *from scratch*, ou *√† partir de rien*, consiste √† apprendre un nouveau mod√®le depuis le d√©but, sans aucune connaissance autre que le jeu d'entra√Ænement.\n",
    "\n",
    "Par facilit√©, nous allons illustrer la capacit√© √† entra√Æner ou am√©liorer des mod√®les existants de spaCy avec un entra√Ænement de ce type, qui n√©cessite une dizaine de minutes de calcul sur un ordinateur portable.\n",
    "Bien entendu, d'autres techniques plus avanc√©es sont possibles, et nous les pr√©senterons rapidement √† la fin de cette section.\n",
    "Notre motivation ici est de vous permettre de prendre en main ce processus, et de l'am√©liorer par vous-m√™mes ensuite.\n",
    "\n",
    "Pour vous permettre d'entra√Æner votre mod√®le, nous vous fournissons un jeu d'entra√Ænement qui contient 70% du jeu de donn√©es ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù, 30% ayant √©t√© r√©serv√©s pour le jeu de test.\n",
    "\n",
    "Les fichiers correspondant aux *train* et *test* *sets* sont disponibles dans le r√©pertoire `dataset/` :\n",
    "- `./dataset/train.spacy` : jeu d'entra√Ænement (*train set*)\n",
    "- `./dataset/test.spacy` : jeu de test (*test set*, aussi appel√© *dev set* ici)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour entra√Æner votre mod√®le avec spaCy, vous allez devoir r√©aliser les actions suivantes :\n",
    "1. Cr√©er un fichier de configuration de base `base_config.cfg` √† l'aide de l'assistant en ligne <https://spacy.io/usage/training#quickstart>,\n",
    "2. Compl√©ter le fichier de configuration avec la commande [`!python -m spacy init fill-config ...`](https://spacy.io/api/cli#init-fill-config),\n",
    "3. Lancer l'entra√Ænement avec la commande [`!python -m spacy train ...`](https://spacy.io/api/cli#train),\n",
    "4. Charger le mod√®le appris avec la fonction [`spacy.load()`](https://spacy.io/api/top-level#spacy.load), l'√©valuer manuellement et l'utiliser sur un fichier jamais vu pendant l'entra√Ænement.\n",
    "\n",
    "Nous stockerons tous les fichiers de configuration et les mod√®les g√©n√©r√©s dans le r√©pertoire `training-scratch/` afin de centraliser l'information √† propos de l'entra√Ænement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Cr√©ez un fichier de configuration √† l'aide de l'assistant\n",
    "\n",
    "Visitez la page <https://spacy.io/usage/training#quickstart> et s√©lectionner les param√®tres suivants :\n",
    "- Language: fran√ßais\n",
    "- Composants: NER seul\n",
    "- Hardware: CPU dans le doute, GPU si vous disposez d'une machine avec un acc√©l√©rateur GPU\n",
    "- Optimize for: efficiency (vous pourrez s√©lectionner \"accuracy\" si vous lancez un entra√Ænement plus long)\n",
    "\n",
    "Ensuite, copiez-collez le contenu du fichier g√©n√©r√© dans la cellule ci-dessous pour cr√©er notre fichier de configuration.  \n",
    "Attention √† ne remplacer que le texte entre les d√©limiteurs `-------8<---------8<----------`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p training-scratch\n",
    "echo '\n",
    "# -------8<---------8<----------\n",
    "# This is an auto-generated partial config. To use it with 'spacy train'\n",
    "# you can run spacy init fill-config to auto-fill all default settings:\n",
    "# python -m spacy init fill-config ./base_config.cfg ./config.cfg\n",
    "[paths]\n",
    "train = null\n",
    "dev = null\n",
    "vectors = null\n",
    "[system]\n",
    "gpu_allocator = null\n",
    "\n",
    "[nlp]\n",
    "lang = \"fr\"\n",
    "pipeline = [\"tok2vec\",\"ner\"]\n",
    "batch_size = 1000\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.tok2vec]\n",
    "factory = \"tok2vec\"\n",
    "\n",
    "[components.tok2vec.model]\n",
    "@architectures = \"spacy.Tok2Vec.v2\"\n",
    "\n",
    "[components.tok2vec.model.embed]\n",
    "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
    "width = ${components.tok2vec.model.encode.width}\n",
    "attrs = [\"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"]\n",
    "rows = [5000, 1000, 2500, 2500]\n",
    "include_static_vectors = false\n",
    "\n",
    "[components.tok2vec.model.encode]\n",
    "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
    "width = 96\n",
    "depth = 4\n",
    "window_size = 1\n",
    "maxout_pieces = 3\n",
    "\n",
    "[components.ner]\n",
    "factory = \"ner\"\n",
    "\n",
    "[components.ner.model]\n",
    "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
    "state_type = \"ner\"\n",
    "extra_state_tokens = false\n",
    "hidden_width = 64\n",
    "maxout_pieces = 2\n",
    "use_upper = true\n",
    "nO = null\n",
    "\n",
    "[components.ner.model.tok2vec]\n",
    "@architectures = \"spacy.Tok2VecListener.v1\"\n",
    "width = ${components.tok2vec.model.encode.width}\n",
    "\n",
    "[corpora]\n",
    "\n",
    "[corpora.train]\n",
    "@readers = \"spacy.Corpus.v1\"\n",
    "path = ${paths.train}\n",
    "max_length = 0\n",
    "\n",
    "[corpora.dev]\n",
    "@readers = \"spacy.Corpus.v1\"\n",
    "path = ${paths.dev}\n",
    "max_length = 0\n",
    "\n",
    "[training]\n",
    "dev_corpus = \"corpora.dev\"\n",
    "train_corpus = \"corpora.train\"\n",
    "\n",
    "[training.optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "\n",
    "[training.batcher]\n",
    "@batchers = \"spacy.batch_by_words.v1\"\n",
    "discard_oversize = false\n",
    "tolerance = 0.2\n",
    "\n",
    "[training.batcher.size]\n",
    "@schedules = \"compounding.v1\"\n",
    "start = 100\n",
    "stop = 1000\n",
    "compound = 1.001\n",
    "\n",
    "[initialize]\n",
    "vectors = ${paths.vectors}\n",
    "# -------8<---------8<----------\n",
    "' > ./training-scratch/base_config.cfg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©ter le fichier de configuration\n",
    "Compl√©tez la commande [`!python -m spacy init fill-config ...`](https://spacy.io/api/cli#init-fill-config) suivante pour indiquer :\n",
    "- le fichier de configuration de base `./training-scratch/base_config.cfg`,\n",
    "- un fichier de configuration cible : nommez-le `config.cfg` et stockez-le dans le m√™me r√©pertoire.\n",
    "\n",
    "N'h√©sitez pas √† consulter la documentation.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```\n",
    "!python -m spacy init fill-config ./training-scratch/base_config.cfg ./training-scratch/config.cfg\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEACHER\n",
    "!python -m spacy init fill-config ___________   ___________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Lancer l'entra√Ænement\n",
    "Compl√©tez la commande [`!python -m spacy train ...`](https://spacy.io/api/cli#train) suivante pour indiquer :\n",
    "- le chemin vers le fichier de configuration\n",
    "- le chemin vers le r√©pertoire de sortie `./training-scratch/output`\n",
    "- le chemin vers le jeu d'entra√Ænement\n",
    "- le chemin vers le jeu de test\n",
    "\n",
    "N'h√©sitez pas √† consulter la documentation.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```\n",
    "!python -m spacy train ./training-scratch/config.cfg --output ./training-scratch/output --paths.train ./dataset/train.spacy --paths.dev ./dataset/test.spacy\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train ________ --output ________ --paths.train ________ --paths.dev ________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ Bravo, vous avez r√©ussi √† entra√Æner un mod√®le ! üéä\n",
    "\n",
    "Deux variantes du mod√®le sont conserv√©es :\n",
    "- la derni√®re version, celle qui est optimis√©e √† chaque √©tape de l'apprentissage\n",
    "- la meilleure version, celle qui a donn√© les meilleurs r√©sultats sur le jeu de test/dev.\n",
    "\n",
    "ü§ì Il est m√™me possible de cr√©er un package Python facile √† partager, sauvegarder et r√©utiliser avec la commande [`spacy package`](https://spacy.io/api/cli#package)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Chargement du mod√®le entra√Æn√©, √©valuation et utilisation\n",
    "\n",
    "Nous allons √† pr√©sent charger et √©valuer le mod√®le qui vient d'√™tre entra√Æn√©.\n",
    "\n",
    "On s√©lectionne le meilleur mod√®le, qui n'est pas forc√©ment le dernier, afin d'esp√©rer les meilleurs r√©sultats possibles.\n",
    "\n",
    "Cette **√©valuation quantitative** sur **le jeu de test** nous permet d'avoir une estimation non biais√©e de la performance de ce mod√®le sur d'autres textes similaires qui n'ont pas √©t√© vus pendant l'entra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = spacy.load(\"./training-scratch/output/model-best\")\n",
    "evaluate(my_model, test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le F-score de ce mod√®le est plus faible, pour les entit√©s de type `LOC`, que les mod√®les d√©j√† disponibles.\n",
    "\n",
    "Il y a plusieurs raisons √† cela :\n",
    "- nous avons entra√Æn√© avec tr√®s peu de donn√©es\n",
    "- nous avons optimis√© l'apprentissage en int√©grant les entit√©s `PER` et `LOC`, et ce mod√®le s'av√®re meilleur sur les entit√©s `PER` que le mod√®le *small* de base ; le choix du crit√®re est important !\n",
    "\n",
    "Toutefois, ce petit mod√®le donne d√©j√† une meilleure pr√©cision (c'est-√†-dire qu'il produit moins de fausses d√©tections) que le petit mod√®le de base. Pour de l'extraction de donn√©es, cela peut d√©j√† √™tre un gain !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut √©galement appeler le mod√®les sur un texte du jeu de test afin d'avoir un **aper√ßu qualitatif** de ses r√©sultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_text = next(test_set.get_docs(my_model.vocab))\n",
    "doc_test = my_model(unseen_text)\n",
    "doc_test.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc_test, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7.4 En r√©sum√© √† propos de l'entra√Ænement\n",
    "\n",
    "Nous avons vu qu'il √©tait simple d'entra√Æner un petit mod√®le *from scratch*, et vous devriez √† pr√©sent √™tre en mesure d'aller plus loin (hors du cadre de cette activit√©) en :\n",
    "- partant non plus de z√©ro, mais √† partir d'un mod√®le d√©j√† entra√Æn√© pour r√©utiliser les connaissances d√©j√† apprises (*transfer learning*)\n",
    "- utiliser un mod√®le plus puissant (mais aussi plus gourmand en ressources de calcul pour l'apprentissage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export des donn√©es pour une utilisation ult√©rieure ‚Äî *‚è±Ô∏è 2 mn*\n",
    "\n",
    "Nous allons stocker les donn√©es produites dans un fichier JSON facile √† r√©utiliser et convertir.\n",
    "\n",
    "Nous allons sauvegarder ce fichier dans votre Drive ou √† l'emplacement que vous indiquerez ci-apr√®s.\n",
    "\n",
    "Nous allons √©galement vous montrer comment t√©l√©charger directement le fichier vers votre machine locale si vous utilisez Google Colab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez les cellules suivantes, en modifiant le chemin vers l'emplacement de sauvegarde du fichier si n√©cessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHEMIN VERS LE FICHIER DE SAUVEGARDE\n",
    "PATH_TO_SAVE_FILE = f\"/gdrive/My Drive/{FOLDER_NAME}/en_french_eltec_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition d'une fonction de sauvegarde\n",
    "import json\n",
    "def save_my_entities(data: list[str], filename: str):\n",
    "    with open(filename, mode='w', encoding=\"utf8\") as out_file:\n",
    "        json.dump(data, out_file, indent=0)\n",
    "    print(f\"Your data was successfully save to '{filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du fichier\n",
    "save_my_entities(all_loc_entities, PATH_TO_SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©chargement direct du fichier depuis la VM Colab\n",
    "files.download(PATH_TO_SAVE_FILE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ C'est tout pour cette fois !\n",
    "\n",
    "Nous esp√©rons que cette activit√© a √©t√© enrichissante.\n",
    "\n",
    "N'h√©sitez pas √† **donner rapidement votre avis anonyme üì¢** via [ce **formulaire** üìù](https://docs.google.com/forms/d/e/1FAIpQLSfS46qZC5Bz7ultNm2tLLYl6b72HonbERt1srpaoLUes-tNJA/viewform?usp=sf_link) pour nous aider √† l'am√©liorer.\n",
    "\n",
    "Finalement, notez que plusieurs points n'ont pas pu √™tre abord√©s ici pour des raisons de temps :\n",
    "- la s√©lection des donn√©es du corpus,\n",
    "- la conversion des donn√©es vers et depuis la plateforme d'annotation,\n",
    "- la pr√©paration des donn√©es d'entra√Ænement et d'√©valuation,\n",
    "- les [matchers](https://spacy.io/api/matcher),\n",
    "- utiliser d'autres outils, comme la biblioth√®que [Transformers d'HuggingFace](https://huggingface.co/transformers/).\n",
    "\n",
    "Nous avons r√©alis√© toutes ces op√©rations pour la pr√©paration de cette activit√©, et vous pourrez regarder nos [notebooks de brouillon](https://github.com/jchazalon/hn-ariane-ner-tuto-2023/tree/main/preparation) si vous le souhaitez, afin de disposer d'exemples de code √† r√©utiliser.\n",
    "\n",
    "üëç Bonne analyse de donn√©es !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hn-ariane-ner-tuto-2023-PwR_0BG5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
